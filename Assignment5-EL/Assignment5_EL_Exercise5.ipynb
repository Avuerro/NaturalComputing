{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Computing - Assignment 5 - Ensemble Learning\n",
    "## Exercise 5\n",
    "#### Submission by group 25 (Chihab Amghane, Max Driessen, Jordy Naus)\n",
    "\n",
    "This file contains our code for exercise 5 of the \"Ensemble Learning\" assignment of the Natural Computing course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report,plot_confusion_matrix\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onehot encoding\n",
    "def onehotencode(string,encoder,possibilities):\n",
    "    encoder = OneHotEncoder()\n",
    "    possibilities =[[x] for x in possibilities]\n",
    "    encoder.fit(possibilities)\n",
    "    return encoder.transform([[string]]).toarray()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_zeros(row,column):\n",
    "    if(type(row[column]) is int):\n",
    "        row[column] = 'N'\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loc = '../../../ensemble_learning/titanic'\n",
    "dataframe_train = pd.read_csv(os.path.join(data_loc,'train.csv'))\n",
    "\n",
    "dataframe_train = dataframe_train.fillna(0)\n",
    "## onehotencode sex\n",
    "onehotencode_sex = pd.get_dummies(dataframe_train['Sex'])\n",
    "dataframe_train['male'] = onehotencode_sex['male']\n",
    "dataframe_train['female'] = onehotencode_sex['female']\n",
    "\n",
    "## onehotencode embarked\n",
    "dataframe_train = dataframe_train.apply(remove_zeros, column='Embarked',axis=1)\n",
    "onehotencode_embarked = pd.get_dummies(dataframe_train['Embarked'])\n",
    "\n",
    "for col in onehotencode_embarked.columns:\n",
    "    dataframe_train[col] = onehotencode_embarked[col]\n",
    "\n",
    "y = dataframe_train['Survived'].to_numpy()\n",
    "dataframe_train = dataframe_train.drop(columns=['PassengerId','Survived','Name', 'Ticket','Cabin','Sex','Embarked'])\n",
    "X = dataframe_train.to_numpy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=1,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(max_depth=5, random_state=0, oob_score=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 60/250 [00:48<04:00,  1.27s/it]"
     ]
    }
   ],
   "source": [
    "min_forest_size = 100\n",
    "max_forest_size = 2500\n",
    "forest_data = {forest_size:{} for forest_size in range(min_forest_size,max_forest_size+100)}\n",
    "forest_predictions = {forest_size:[] for forest_size in range(min_forest_size,max_forest_size+100)}\n",
    "for forest_size in tqdm(range(min_forest_size,max_forest_size+100,10)):\n",
    "    clf.set_params(n_estimators=forest_size)\n",
    "    clf.fit(X_train,y_train)\n",
    "    data_dict = {}\n",
    "    \n",
    "    ## We are interested in accuracy,and oob scores\n",
    "    predictions = clf.predict(X_test)\n",
    "    accuracy = clf.score(X_test,y_test)\n",
    "    oob_error = 1 - clf.oob_score_\n",
    "    \n",
    "    forest_predictions[forest_size] = predictions\n",
    "    data_dict['accuracy'] = accuracy\n",
    "    data_dict['oob_error'] = oob_error\n",
    "    forest_data[forest_size] = data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = [forest_data[x]['accuracy'] for x in range(min_forest_size,max_forest_size+100,10)]\n",
    "oob_errors = [forest_data[x]['oob_error'] for x in range(min_forest_size,max_forest_size+100,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(min_forest_size,max_forest_size+100,10),accuracies)\n",
    "plt.title('Overview of the effect of the number of estimators on the accuracy')\n",
    "plt.xlabel('number of trees')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "plt.plot(range(min_forest_size,max_forest_size+100,10),oob_errors,'tab:orange')\n",
    "plt.title('Overview of the effect of the number of estimators on the OOB error')\n",
    "plt.xlabel('number of trees')\n",
    "plt.ylabel('OOB error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The index of the highest accuracy {np.argmax(np.array(accuracies))}\")\n",
    "print(f\"The index of the lowest ebo {np.argmin(np.array(oob_errors))}\")\n",
    "print(f\"the number of trees {range(min_forest_size,max_forest_size+100,10)[51]}\")\n",
    "print(f\"oob error {oob_errors[180]}\")\n",
    "print(accuracies[180])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_nr_features = 1\n",
    "max_nr_features = 7\n",
    "features_forest_data = {forest_size:{} for forest_size in range(min_nr_features,max_nr_features+1)}\n",
    "features_forest_predictions = {forest_size:[] for forest_size in range(min_nr_features,max_nr_features+1)}\n",
    "for nr_of_features in tqdm(range(min_nr_features,max_nr_features)):\n",
    "    clf.set_params(n_estimators=610, max_features = nr_of_features)\n",
    "    clf.fit(X_train,y_train)\n",
    "    data_dict = {}\n",
    "\n",
    "    ## We are interested in accuracy,and oob scores\n",
    "    predictions = clf.predict(X_test)\n",
    "    accuracy = clf.score(X_test,y_test)\n",
    "    oob_error = 1 - clf.oob_score_\n",
    "\n",
    "    features_forest_predictions[nr_of_features] = predictions\n",
    "    data_dict['accuracy'] = accuracy\n",
    "    data_dict['oob_error'] = oob_error\n",
    "    features_forest_data[nr_of_features] = data_dict    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_accuracies = [features_forest_data[x]['accuracy'] for x in range(min_nr_features,max_nr_features)]\n",
    "feature_oob_errors = [features_forest_data[x]['oob_error'] for x in range(min_nr_features,max_nr_features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(min_nr_features,max_nr_features),feature_accuracies)\n",
    "plt.title('Overview of the effect of the number of features on the accuracy')\n",
    "plt.xlabel('number of features')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "plt.plot(range(min_nr_features,max_nr_features),feature_oob_errors,'tab:orange')\n",
    "plt.title('Overview of the effect of the number of features on the OOB error')\n",
    "plt.xlabel('number of features')\n",
    "plt.ylabel('OOB error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.set_params(n_estimators=610, max_features = 2)\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "accuracy = clf.score(X_test,y_test)\n",
    "oob_error = 1 - clf.oob_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(clf,X_test,y_test, display_labels=['Dead','Survived'],values_format='0.5g', cmap=plt.cm.Blues)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predictions, target_names=[\"Dead\", \"Survived\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## class imbalance\n",
    "print(y[y==0].shape)\n",
    "print(y[y==1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = clf.feature_importances_\n",
    "sorted_ids = np.argsort(feature_importances)\n",
    "feature_names = dataframe_train.columns\n",
    "fig,ax = plt.subplots()\n",
    "y_ticks = range(0, len(feature_importances))\n",
    "ax.barh(y_ticks,feature_importances[sorted_ids])\n",
    "ax.set_yticklabels(feature_names[sorted_ids])\n",
    "ax.set_yticks(y_ticks)\n",
    "ax.set_ylabel('Feature')\n",
    "ax.set_xlabel('Importance')\n",
    "fig.suptitle('Feature Importance')\n",
    "# fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "result = permutation_importance(clf, X_test, y_test, n_repeats=10)\n",
    "permutation_importances = result.importances_mean\n",
    "sorted_ids = np.argsort(permutation_importances)\n",
    "fix,ax = plt.subplots()\n",
    "ax.boxplot(result.importances[sorted_ids].T, vert=False, labels=feature_names[sorted_ids])\n",
    "ax.set_title('Permutation Importances on the Test set')\n",
    "ax.set_ylabel('Feature')\n",
    "ax.set_xlabel('Permutation Importance')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

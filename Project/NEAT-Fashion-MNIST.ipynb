{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'fashion_mnist' from 'keras.datasets' (/Users/jordynaus/Library/Python/3.8/lib/python/site-packages/keras/datasets/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-09448f63be28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#!pip3 install neat-python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfashion_mnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mssl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'fashion_mnist' from 'keras.datasets' (/Users/jordynaus/Library/Python/3.8/lib/python/site-packages/keras/datasets/__init__.py)"
     ]
    }
   ],
   "source": [
    "#!pip3 install neat-python\n",
    "\n",
    "from tensorflow.keras.datasets import mnist, fashion_mnist\n",
    "import numpy as np\n",
    "import ssl\n",
    "import neat\n",
    "from skimage.transform import rescale\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset parameters\n",
    "STANDARD_IMAGE_SIZE = 28\n",
    "DESIRED_IMAGE_SIZE = 16\n",
    "N_CLASSES_TO_USE = 10\n",
    "\n",
    "RESCALE_FACTOR = DESIRED_IMAGE_SIZE/STANDARD_IMAGE_SIZE\n",
    "N_PIXELS = DESIRED_IMAGE_SIZE**2\n",
    "\n",
    "# How many samples to test:\n",
    "N_SAMPLES_TO_TEST = 1000\n",
    "\n",
    "# Simulation Parameters\n",
    "NR_GENERATIONS = 4096\n",
    "CONFIG_FILE = 'NEAT-configs/mnist-wann'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trim down Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure correct number of classes\n",
    "X_train = X_train[Y_train < N_CLASSES_TO_USE]\n",
    "Y_train = Y_train[Y_train < N_CLASSES_TO_USE]\n",
    "X_test = X_test[Y_test < N_CLASSES_TO_USE]\n",
    "Y_test = Y_test[Y_test < N_CLASSES_TO_USE]\n",
    "\n",
    "# Extract and print the number of training and testing samples remaining\n",
    "n_samples_train = X_train.shape[0]\n",
    "n_samples_test = X_test.shape[0]\n",
    "print(f\"Training samples remaining: {n_samples_train}\")\n",
    "print(f\"Testing samples remaining: {n_samples_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescale Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescaling to the desired size\n",
    "def rescale_images(images, do_anti_aliasing=False):\n",
    "    return np.array([rescale(image, RESCALE_FACTOR, anti_aliasing=do_anti_aliasing) for image in images])\n",
    "\n",
    "# Rescale X_train and X_test\n",
    "X_train_small = rescale_images(X_train)\n",
    "X_test_small = rescale_images(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "def normalize(images):\n",
    "    return (images - np.mean(images, axis=0))/(np.std(images, axis=0) + 0.000001)\n",
    "\n",
    "# Normalize X_train_small and X_test_small\n",
    "X_train_norm = normalize(X_train_small)\n",
    "X_test_norm = normalize(X_test_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot original and reshaped image\n",
    "def plot_comparison(idx_to_plot, lists, titles):\n",
    "    n_plots = len(lists)\n",
    "    fig, ax = plt.subplots(1,n_plots, figsize=(10,10/n_plots))\n",
    "    for i in range(n_plots):\n",
    "        ax[i].imshow(lists[i][idx_to_plot])\n",
    "        ax[i].set_title(titles[i])\n",
    "        ax[i].axis(\"off\")\n",
    "    fig.suptitle(f\"Preprocessing of sample {idx_to_plot}\",y=1)\n",
    "    plt.show()\n",
    "    \n",
    "plot_comparison(37,\n",
    "                [X_train, X_train_small, X_train_norm],\n",
    "                [f\"Original {STANDARD_IMAGE_SIZE}x{STANDARD_IMAGE_SIZE} image\",\n",
    "                 f\"Rescaled {DESIRED_IMAGE_SIZE}x{DESIRED_IMAGE_SIZE} image\",\n",
    "                 f\"Normalized {DESIRED_IMAGE_SIZE}x{DESIRED_IMAGE_SIZE} image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace and reshape X_train and X_test, for convenience\n",
    "X_train = X_train_norm.reshape(n_samples_train, DESIRED_IMAGE_SIZE**2)\n",
    "X_test = X_test_norm.reshape(n_samples_test, DESIRED_IMAGE_SIZE**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Run Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(config_file):\n",
    "    # Load configuration.\n",
    "    config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                         neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
    "                         config_file)\n",
    "\n",
    "    # Create the population, which is the top-level object for a NEAT run.\n",
    "    p = neat.Population(config)\n",
    "    \n",
    "    # Add a stdout reporter to show progress in the terminal.\n",
    "    p.add_reporter(neat.StdOutReporter(True))\n",
    "    stats = neat.StatisticsReporter()\n",
    "    \n",
    "    p.add_reporter(stats)\n",
    "    p.add_reporter(neat.Checkpointer(50, filename_prefix='NEAT-checkpoints/neat-checkpoint-10-classes-'))\n",
    "    \n",
    "    \n",
    "    # Run for up to NR_GENERATIONS generations.\n",
    "    winner = p.run(eval_genomes, NR_GENERATIONS)\n",
    "    stats.save_genome_fitness(filename=\"NEAT-results/fitness_history.csv\")\n",
    "    \n",
    "    with open('NEAT-results/best_genomes', 'wb') as f:\n",
    "        best_genomes = stats.best_genomes(10)\n",
    "        pickle.dump(best_genomes,f)\n",
    "    \n",
    "    \n",
    "    # Display the winning genome.\n",
    "    print('\\nBest genome:\\n{!s}'.format(winner))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sigmoid(output):\n",
    "    output = [min(709., x) for x in output]\n",
    "    output = [max(-709., x) for x in output]\n",
    "    return [1 /(1 + math.exp(-x)) for x in output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_genomes(genomes, config):\n",
    "    \n",
    "    sample_indices = []\n",
    "    n_samples_per_class = int(N_SAMPLES_TO_TEST/N_CLASSES_TO_USE)\n",
    "    for c in range(N_CLASSES_TO_USE):\n",
    "        c_indices = np.where(Y_train == c)[0]\n",
    "        assert len(c_indices) >= n_samples_per_class, \\\n",
    "            f\"Class {c} has too few elements to reach the desired number of evaluation samples\"\n",
    "        sample_indices.extend(np.random.permutation(c_indices)[:n_samples_per_class])\n",
    "    \n",
    "    # Compute cross-entropy loss for each of the samples\n",
    "    losses = []\n",
    "    for i in sample_indices:\n",
    "        X_sample, Y_sample = X_train[i], Y_train[i]\n",
    "        \n",
    "    \n",
    "    for genome_id, genome in genomes:\n",
    "        genome.fitness = 0.\n",
    "        net = neat.nn.FeedForwardNetwork.create(genome, config)\n",
    "        nr_correct = 0.\n",
    "        for i in sample_indices:\n",
    "            train, label = X_train[i], Y_train[i]\n",
    "            output = net.activate(train)\n",
    "            if np.argmax(sigmoid(output)) == label:\n",
    "                nr_correct += 1.\n",
    "\n",
    "        genome.fitness = (nr_correct / N_SAMPLES_TO_TEST)          \n",
    "    \n",
    "        \n",
    "        \n",
    "#  OLD FITNESS:\n",
    "#         for i in sample_indices:\n",
    "#             train, label = X_train[i], Y_train[i]\n",
    "#             output = net.activate(train)\n",
    "#             genome.fitness -= (np.argmax(output) - label) ** 2 \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run(CONFIG_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = np.genfromtxt('NEAT-results/fitness_history.csv', delimiter='')\n",
    "best_fitness = history[:,0]\n",
    "avg_fitness = history[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(best_fitness, label = 'Best Fitness')\n",
    "plt.plot(avg_fitness, label = 'Average Fitness')\n",
    "plt.title('Best and Average Fitness over Generations')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Fitness (Accuracy)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Test Fittest Member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def test_fittest(config_file):\n",
    "    config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                         neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
    "                         config_file)\n",
    "    \n",
    "    preds_test = []\n",
    "    preds_train = []\n",
    "    train_correct = 0.\n",
    "    test_correct = 0. \n",
    "    fittest_genome = pickle.load( open('NEAT-results/best_genomes', 'rb'))[0]\n",
    "    #print(fittest_genome)\n",
    "    net = neat.nn.FeedForwardNetwork.create(fittest_genome, config)\n",
    "        \n",
    "    for train, label in zip(X_train, Y_train):\n",
    "        output = np.argmax(sigmoid(net.activate(train)))\n",
    "        preds_train.append(output)\n",
    "        if output == label:\n",
    "            train_correct += 1.\n",
    "    train_acc = train_correct / len(X_train)\n",
    "    \n",
    "    for test, label in zip(X_test, Y_test):\n",
    "        output = np.argmax(sigmoid(net.activate(test)))\n",
    "        preds_test.append(output)\n",
    "        if output == label:\n",
    "            test_correct += 1.\n",
    "    test_acc = test_correct / len(X_test)\n",
    "        \n",
    "    print(\"Train Accuracy = {}\".format(train_acc))\n",
    "    print(\"Test Accuracy = {}\".format(test_acc))\n",
    "    \n",
    "    return preds_train, preds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train, preds_test = test_fittest(CONFIG_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_train = confusion_matrix(Y_train, preds_train, labels=range(N_CLASSES_TO_USE))\n",
    "cm_test = confusion_matrix(Y_test, preds_test, labels=range(N_CLASSES_TO_USE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure\n",
    "fig, ax = plt.subplots(1,2, figsize=(11,4))\n",
    "\n",
    "# Plot confusion matrix for training data\n",
    "sns.heatmap(cm_train, annot=True, fmt='g', ax=ax[0], cmap=\"Blues\")\n",
    "ax[0].set_xlabel('Predicted labels')\n",
    "ax[0].set_ylabel('True labels')\n",
    "ax[0].set_title('Confusion matrix for training data')\n",
    "\n",
    "# Plot confusion matrix for validation data\n",
    "sns.heatmap(cm_test, annot=True, fmt='g', ax=ax[1], cmap=\"Blues\")\n",
    "ax[1].set_xlabel('Predicted labels')\n",
    "ax[1].set_ylabel('True labels')\n",
    "ax[1].set_title('Confusion matrix for test data')\n",
    "\n",
    "# Show the result\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting Fittest Genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fittest_genome = pickle.load( open('NEAT-results/best_genomes', 'rb'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(fittest_genome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_input_pixels = []\n",
    "for cg in fittest_genome.connections.values():\n",
    "    if cg.enabled:\n",
    "        used_input_pixels.append(cg.key[0])\n",
    "print(used_input_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tallies = np.zeros(X_train.shape[1])\n",
    "for arg in used_input_pixels:\n",
    "    input_tallies[arg] += 1\n",
    "plt.imshow( input_tallies.reshape(16,16) )\n",
    "plt.title('Used Input Pixels')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

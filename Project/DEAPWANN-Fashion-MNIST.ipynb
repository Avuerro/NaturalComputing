{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Computing - Project\n",
    "#### Submission by group 25 (Chihab Amghane, Max Driessen, Jordy Naus)\n",
    "\n",
    "The code below uses the [DEAP framework](https://github.com/deap/deap), which is an intuitive framework for evolutionary algorithms and genetic programming. We adapted several components of this framework to match more closely with the [WANN implementation](https://github.com/google/brain-tokyo-workshop/tree/master/WANNRelease)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEAP\n",
    "from deap import gp, base, tools, creator, algorithms\n",
    "\n",
    "# Data processing and plotting\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Requirements for the algorithm\n",
    "from operator import attrgetter\n",
    "from functools import partial\n",
    "\n",
    "# Standard python imports\n",
    "import random, pickle, math, re, os\n",
    "import numpy as np\n",
    "\n",
    "# Magic for inline plots\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp(x):\n",
    "    return np.exp(np.clip(x, -float('inf'), 709.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "DATASET = \"Fashion-MNIST\" # choose from {\"MNIST\", \"Fashion-MNIST\"} \n",
    "N_CLASSES_TO_USE = 10 # at most 10\n",
    "\n",
    "# Individual trees\n",
    "P_INITIAL_CONNECTION = 0.05\n",
    "\n",
    "# Fitness\n",
    "SAMPLE_SIZE = 200\n",
    "WEIGHTS_TO_TEST = [-2, -1, 1, 2] # -0.5 and 0.5 are not used due to long runtime\n",
    "\n",
    "# Parent selection\n",
    "TOURNAMENT_SIZE = 32\n",
    "\n",
    "# Mutation (probabilities should sum to 1)\n",
    "P_MUTATE_ACTIVATION = 0.5\n",
    "P_ADD_NODE = 0.25\n",
    "P_ADD_CONNECTION = 0.2\n",
    "P_ENABLE_CONNECTION = 0.05\n",
    "\n",
    "# Evolution\n",
    "POPULATION_SIZE = 250\n",
    "N_GENERATIONS = 1000\n",
    "CULL_RATIO = 0.2\n",
    "ELITE_RATIO = 0.2\n",
    "\n",
    "# Filenames\n",
    "RESULTS_FILENAME = f\"DEAPWANN-{DATASET}-results.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the correct data filename\n",
    "filename = f\"{DATASET}-{N_CLASSES_TO_USE}.pkl\"\n",
    "\n",
    "# If the data has not yet been preprocessed in the specified way, do so now\n",
    "if not os.path.exists(os.path.join(\"data\", filename)):\n",
    "    print(\"Preprocessed dataset does not exist yet, creating now.\")\n",
    "    os.system(f\"python Preprocessing.py -d {DATASET} -c {N_CLASSES_TO_USE}\")\n",
    "\n",
    "# Load the preprocessed data\n",
    "with open(os.path.join(\"data\", filename), \"rb\") as f:\n",
    "    (X_train, Y_train), (X_test, Y_test) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define aggregator (weighted sum)\n",
    "def aggregate(w, args):\n",
    "    return w*sum(args)\n",
    "\n",
    "# Define operators (with a variable number of inputs)\n",
    "def linear(w, *args):\n",
    "    return aggregate(w, args)\n",
    "\n",
    "def step(w, *args):\n",
    "    return float(aggregate(w, args) > 0)\n",
    "\n",
    "def sine(w, *args):\n",
    "    return np.sin(np.pi*aggregate(w, args))\n",
    "\n",
    "def gaussian(w, *args):\n",
    "    return exp(-np.multiply(aggregate(w, args), aggregate(w, args))/2.0)\n",
    "\n",
    "def tanh(w, *args):\n",
    "    return np.tanh(aggregate(w, args))\n",
    "\n",
    "def sigmoid(w, *args):\n",
    "    return (np.tanh(aggregate(w, args)/2.0) + 1.0)/2.0\n",
    "\n",
    "def inverse(w, *args):\n",
    "    return -aggregate(w, args)\n",
    "\n",
    "def absolute(w, *args):\n",
    "    return abs(aggregate(w, args))\n",
    "\n",
    "def relu(w, *args):\n",
    "    return np.maximum(0.0, aggregate(w, args))\n",
    "\n",
    "def cosine(w, *args):\n",
    "    return np.cos(np.pi*aggregate(w, args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dictionary of functions for compiling\n",
    "function_context = {'linear':linear, 'relu':relu, 'step':step, 'sine':sine, 'gaussian':gaussian, 'tanh':tanh,  \n",
    "                    'sigmoid':sigmoid, 'inverse':inverse, 'absolute':absolute, 'cosine':cosine}\n",
    "\n",
    "# Create lists of function and argument names\n",
    "function_names = list(function_context.keys())\n",
    "argument_names = [f\"ARG{i}\" for i in range(X_train.shape[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining individuals\n",
    "\n",
    "##### Defining nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic Node class\n",
    "class Node:\n",
    "    def __init__(self, name):\n",
    "        # Each node has a name and a list of parents\n",
    "        self.name = name\n",
    "        self.parents = []\n",
    "    \n",
    "    def __str__(self):\n",
    "        raise NotImplementedError(\"String function is only implemented for subclasses\")\n",
    "\n",
    "# Class for terminal nodes (inputs)\n",
    "class TerminalNode(Node):\n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "\n",
    "    def __str__(self):\n",
    "        # Terminal nodes are simply formatted as their name (e.g. \"ARG42\")\n",
    "        return self.name\n",
    "\n",
    "# Class for non-terminal nodes (hidden + outputs)\n",
    "class NonterminalNode(Node):\n",
    "    def __init__(self, name):\n",
    "        # Non-terminal nodes also have lists of children and disabled children\n",
    "        super().__init__(name)\n",
    "        self.children = []\n",
    "        self.disabled = []\n",
    "\n",
    "    def __str__(self):\n",
    "        # Non-terminal nodes are formatted as \"name(child1, child2, ...)\"\n",
    "        return f\"{self.name}(w, {', '.join([str(child) for child in self.children])})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Defining individuals/multi-class trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for multi-output trees\n",
    "class MultiClassTree:\n",
    "    def __init__(self, n_inputs, n_outputs, p_initial_connection):\n",
    "        # Initialize lists of input, output and internal nodes\n",
    "        self.inputs = [TerminalNode(argument_names[i]) for i in range(n_inputs)]\n",
    "        self.outputs = [NonterminalNode(\"linear\") for _ in range(n_outputs)]\n",
    "        self.hidden = []\n",
    "        self.born = -1\n",
    "        \n",
    "        # Add initial connections\n",
    "        self.n_connections = 0\n",
    "        for output in self.outputs:\n",
    "            # With a chance of P_INITIAL_CONNECTION, the connection is enabled, otherwhise it is disabled\n",
    "            for child in self.inputs:\n",
    "                if random.random() < P_INITIAL_CONNECTION:\n",
    "                    output.children.append(child)\n",
    "                else:\n",
    "                    output.disabled.append(child)\n",
    "                child.parents.append(output)\n",
    "                \n",
    "            # If an output has no enabled children, one of the children is enabled to make the tree valid\n",
    "            if not output.children:\n",
    "                child = random.choice(self.inputs)\n",
    "                output.disabled.remove(child)\n",
    "                output.children.append(child)\n",
    "            \n",
    "            # Update the number of enabled connections in the tree\n",
    "            self.n_connections += len(output.children)\n",
    "\n",
    "    def __str__(self):\n",
    "        # Printing the tree only prints the number of hidden nodes and enabled connections\n",
    "        return f\"MultiClassTree with {len(self.hidden)} hidden nodes and {self.n_connections} connections\"\\\n",
    "                + (f\", born in generation {self.born}\" if self.born >= 0 else \"\")\n",
    "    \n",
    "    def get_strings(self):\n",
    "         # (Recursively) parsing output function strings, to parse the tree for evaluation\n",
    "        try:\n",
    "            return [str(output) for output in self.outputs]\n",
    "        except RecursionError:\n",
    "            print(\"Maximum recursion depth reached\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initializing the DEAP toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialize the toolbox which will contain all sorts of functions for the genetic programming process\n",
    "toolbox = base.Toolbox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classes for fitness and individuals (using DEAP's creator module)\n",
    "creator.create(\"Fitness\", base.Fitness, weights=(-1.0, -1.0))\n",
    "creator.create(\"Individual\", MultiClassTree, fitness=creator.Fitness, rank=-1) # An individual is a multi-class tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how to initialize an individual or population\n",
    "toolbox.register(\"individual\", creator.Individual, X_train.shape[1], N_CLASSES_TO_USE, P_INITIAL_CONNECTION)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitness function\n",
    "\n",
    "##### Compiling multi-class trees into functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling a tree into a function\n",
    "def compile_multiclasstree(tree):\n",
    "    # Parse trees to strings for all outputs\n",
    "    strings = tree.get_strings()\n",
    "    \n",
    "    # Convert the string to lambda functions using eval() and the proper function context\n",
    "    funcs = [eval(f\"lambda w, {', '.join(argument_names)}: {string}\", function_context, {}) for string in strings]\n",
    "    \n",
    "    # Create the function, which applies softmax over the outputs of the created lambda functions\n",
    "    def func(w, args):\n",
    "        def _softmax(x):\n",
    "            return exp(x)/np.sum(exp(x), axis=0)\n",
    "        return _softmax([f(w, *args) for f in funcs])\n",
    "    \n",
    "    # Return the created function\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the compile function to toolbox\n",
    "toolbox.register(\"compile\", compile_multiclasstree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Defining the fitness function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(seed, sample_size):\n",
    "     # Ensure all individuals in a generation can be tested on the same samples\n",
    "    if seed >=0:\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "    # Create a list of indices of samples to test, ensuring an equal number of samples from each class\n",
    "    sample_indices = []\n",
    "    samples_per_class = int(sample_size/N_CLASSES_TO_USE)\n",
    "    for c in range(N_CLASSES_TO_USE):\n",
    "        c_indices = np.where(Y_train == c)[0]\n",
    "        assert len(c_indices) >= samples_per_class, \\\n",
    "            f\"Class {c} has too few elements to reach the desired number of evaluation samples\"\n",
    "        sample_indices.extend(np.random.permutation(c_indices)[:samples_per_class])\n",
    "    \n",
    "    # Return the list of sample indices\n",
    "    return sample_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define fitness function (cross-entropy loss & inversed number of connections)\n",
    "def fitness(individual, sample_indices, weights_to_test):\n",
    "    # Compile the functions corresponding to the individual\n",
    "    func = toolbox.compile(individual)\n",
    "    \n",
    "    # Define how to compute cross-entropy\n",
    "    def _cross_entropy(pred, label):\n",
    "        return -np.log(pred[label])\n",
    "    \n",
    "    # Compute cross-entropy loss for each of the samples\n",
    "    results = []\n",
    "    for w in weights_to_test:\n",
    "        WEIGHT=w\n",
    "        w_results = [_cross_entropy(func(w, X_train[i]), Y_train[i]) for i in sample_indices]\n",
    "        results.append(np.average(w_results))\n",
    "    \n",
    "    # Return the average and best cross-entropy loss\n",
    "    return (np.average(results), np.min(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the sample generator and fitness function to the toolbox\n",
    "toolbox.register(\"get_sample\", get_sample, sample_size=SAMPLE_SIZE)\n",
    "toolbox.register(\"evaluate\", fitness, weights_to_test=WEIGHTS_TO_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolution components\n",
    "\n",
    "##### Parent selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how to select parents (tournament selection based on NSGA2 rank)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=TOURNAMENT_SIZE, fit_attr=\"rank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutating the activation function of a hidden node\n",
    "def _mutate_activation(tree):\n",
    "    # If the tree has no hidden nodes, do nothing\n",
    "    if not tree.hidden:\n",
    "        return\n",
    "        \n",
    "    # Select a random node and give it a different activation function\n",
    "    node = random.choice(tree.hidden)\n",
    "    node.name = random.choice([name for name in function_names if not name == node.name])\n",
    "\n",
    "\n",
    "# Adding a node to the tree\n",
    "def _add_node(tree):\n",
    "    # Select a random parent-child pair between which to place a node\n",
    "    parent = random.choice(tree.outputs + tree.hidden)\n",
    "    child = random.choice(parent.children)\n",
    "        \n",
    "    # Disable the connection between the parent and the child\n",
    "    parent.children.remove(child)\n",
    "    parent.disabled.append(child)\n",
    "\n",
    "    # Create a new node with a random activation function and add it to the tree\n",
    "    new_node = NonterminalNode(random.choice(function_names))\n",
    "    tree.hidden.append(new_node)\n",
    "        \n",
    "    # Update the parent/child relations\n",
    "    parent.children.append(new_node)\n",
    "    new_node.parents.append(parent)\n",
    "    new_node.children.append(child)\n",
    "    child.parents.append(new_node)\n",
    "        \n",
    "    # Update the number of enabled connections\n",
    "    tree.n_connections += 1\n",
    "\n",
    "    \n",
    "# Adding a connection in the tree\n",
    "def _add_connection(tree):\n",
    "    # Function that checks if node1 is an ancestor of node 2\n",
    "    def _is_ancestor(node1, node2):\n",
    "        return node1 in [node2] + node2.parents or any([_is_ancestor(node1, node3) for node3 in node2.parents])\n",
    "    \n",
    "    # Find a valid parent-child pair for a connection, respecting the feed-forward property (no loops)\n",
    "    valid_connection = False\n",
    "    n_attempts = 0\n",
    "    while not valid_connection and n_attempts < 500:\n",
    "        parent = random.choice(tree.outputs + tree.hidden)\n",
    "        child = random.choice(tree.inputs + tree.hidden)\n",
    "        valid_connection = not _is_ancestor(child, parent) # Connection is valid if child is not an ancestor of parent\n",
    "        n_attempts += 1\n",
    "    \n",
    "    # If a valid connection was found, update the parent/child relations and the number of enabled connections\n",
    "    if n_attempts < 500:\n",
    "        child.parents.append(parent)\n",
    "        parent.children.append(child)\n",
    "        tree.n_connections += 1\n",
    "\n",
    "\n",
    "# Enable a disabled connection (created during initialization or when adding a node)\n",
    "def _enable_connection(tree):\n",
    "    # Check if there are any nodes with disabled connections; if not, do nothing\n",
    "    parents_with_disabled = [node for node in tree.outputs + tree.hidden if node.disabled]\n",
    "    if not parents_with_disabled:\n",
    "        return\n",
    "    \n",
    "    # Select a random disabled parent-child pair\n",
    "    parent = random.choice(parents_with_disabled)\n",
    "    child = random.choice(parent.disabled)\n",
    "    \n",
    "    # Enable the corresponding connection and update the number of enabled connections\n",
    "    parent.disabled.remove(child)\n",
    "    parent.children.append(child)\n",
    "    tree.n_connections += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(tree):\n",
    "    # Copy the parent tree\n",
    "    tree = toolbox.clone(tree)\n",
    "        \n",
    "    # Create lists of the various mutation functions and the corresponding probabilities\n",
    "    mutation_functions = [_mutate_activation, _add_node, _add_connection, _enable_connection]\n",
    "    probabilities = [P_MUTATE_ACTIVATION, P_ADD_NODE, P_ADD_CONNECTION, P_ENABLE_CONNECTION]\n",
    "    \n",
    "    # Ensure probabilities sum to 1\n",
    "    assert sum(probabilities) == 1, \"Mutation probabilities should sum to 1\"\n",
    "    \n",
    "    # Choose a mutation function using the provided probabilities and execute it\n",
    "    mutation_function, = random.choices(mutation_functions, probabilities, k=1)\n",
    "    mutation_function(tree)\n",
    "    \n",
    "    # Return the resulting tree\n",
    "    return tree,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the mutate function to the toolbox\n",
    "toolbox.register(\"mutate\", mutate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe which kinds of statistics to keep track of\n",
    "stats_avgfit = tools.Statistics(key = lambda ind: ind.fitness.values[0])\n",
    "stats_bestfit = tools.Statistics(key = lambda ind: ind.fitness.values[1])\n",
    "stats_connections = tools.Statistics(key = lambda ind: ind.n_connections)\n",
    "stats_hidden = tools.Statistics(key = lambda ind: len(ind.hidden))\n",
    "\n",
    "# Combine statistics into a single multistatistics object\n",
    "mstats = tools.MultiStatistics(avg_fitness=stats_avgfit, best_fitness=stats_bestfit, \n",
    "                               hidden=stats_hidden, connections=stats_connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe metrics to keep track of for each statistic\n",
    "mstats.register(\"avg\", np.mean)\n",
    "mstats.register(\"std\", np.std)\n",
    "mstats.register(\"min\", np.min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the genetic programming algorithm\n",
    "\n",
    "##### Defining the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eaWann(population, toolbox, ngen, cull_ratio, elite_ratio, stats=None, halloffame=None, verbose=True):\n",
    "    \"\"\"\n",
    "    Evolutionary algorithm for Weight Agnostic Neural Networks (WANNs)\n",
    "    Based on the algorithms provided by DEAP, as well as the WANN implementation\n",
    "    \n",
    "    The basic idea is as follows:\n",
    "    1. Sort the population based on fitness (using NSGA2)\n",
    "    2. Remove the worst individuals\n",
    "    3. Copy the best individuals directly to the next generation\n",
    "    4. Perform tournament selection to create the remaining offspring\n",
    "    5. Evaluate all individuals in the new population (each individual is tested on the same sample)\n",
    "    6. Repeat from 1\n",
    "    \n",
    "    Parameters:\n",
    "    population: the intial population\n",
    "    toolbox: the DEAP toolbox containing functions for parent selection, mutation etc.\n",
    "    ngen: number of generations to run the algorithm for\n",
    "    cull_ratio: fraction of the population that will be thrown away every generation (worst individuals)\n",
    "    elite_ratio: fraction of the population that will be directly copied to the next generation (best individuals)\n",
    "    stats: (Multi)Statistics object, keeping track of evolution statistics\n",
    "    halloffame: List containing the best individuals that ever lived\n",
    "    verbose: whether or not to print statistics\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize logbook and set the correct headers\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = ['gen'] + ['avg_fitness', 'best_fitness', 'connections', 'hidden'] if stats else []\n",
    "    for field in stats.fields:\n",
    "        if \"fitness\" in field:\n",
    "            logbook.chapters[field].header = \"min\", \"avg\", \"std\"\n",
    "        else:\n",
    "            logbook.chapters[field].header = \"avg\", \"std\"\n",
    "\n",
    "    # Evaluate all individuals using the same sample\n",
    "    sample = toolbox.get_sample(0)\n",
    "    fitnesses = toolbox.map(partial(toolbox.evaluate, sample_indices=sample), population)\n",
    "    for ind, fit in zip(population, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "        ind.born = 0\n",
    "\n",
    "    # Update hall of fame\n",
    "    if halloffame is not None:\n",
    "        halloffame.update(population)\n",
    "        \n",
    "    # Record and print performance if applicable\n",
    "    record = stats.compile(population) if stats else {}\n",
    "    logbook.record(gen=0, **record)\n",
    "    if verbose:\n",
    "        print(logbook.stream)\n",
    "\n",
    "    # Begin the generational process\n",
    "    for gen in range(1, ngen + 1): \n",
    "        \n",
    "        # Initialize offspring and determine offspring size\n",
    "        offspring = []\n",
    "        population_size = len(population)\n",
    "        \n",
    "        # Rank the population and update rank values (tournament selection prefers individuals with bigger rank)\n",
    "        ranked_population = tools.selNSGA2(population, population_size)\n",
    "        for ind, rank in zip(ranked_population, reversed(range(population_size))):\n",
    "            ind.rank = rank\n",
    "        \n",
    "        # Culling - remove worst performing individuals\n",
    "        number_to_cull = int(cull_ratio*population_size)\n",
    "        ranked_population = ranked_population[:population_size-number_to_cull]\n",
    "        \n",
    "        # Elitism - select and copy best performing individuals\n",
    "        number_of_elites = int(elite_ratio*population_size)\n",
    "        for i in range(number_of_elites):\n",
    "            copy = toolbox.clone(ranked_population[i])\n",
    "            del copy.fitness.values # Will be re-evaluated using this generation's sample\n",
    "            offspring.append(copy)\n",
    "            \n",
    "        # Compute number of offspring that still need to be generated\n",
    "        offspring_to_generate = population_size - number_of_elites\n",
    "            \n",
    "        # Select parents via (NSGA2 rank-based) tournament selection\n",
    "        parents = toolbox.select(ranked_population, offspring_to_generate)\n",
    "        \n",
    "        # Mutate parents to obtain children\n",
    "        for parent in parents:\n",
    "            child, = toolbox.mutate(parent)\n",
    "            del child.fitness.values\n",
    "            child.born = gen\n",
    "            offspring.append(child)\n",
    "\n",
    "        # Evaluate all individuals in the offspring using the same sample\n",
    "        sample = toolbox.get_sample(gen)\n",
    "        fitnesses = toolbox.map(partial(toolbox.evaluate, sample_indices=sample), offspring)\n",
    "        for ind, fit in zip(offspring, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        # Update the hall of fame with the generated individuals\n",
    "        if halloffame is not None:\n",
    "            halloffame.update(offspring)\n",
    "\n",
    "        # Replace the current population by the offspring\n",
    "        population[:] = offspring\n",
    "\n",
    "        # Append the current generation statistics to the logbook\n",
    "        record = stats.compile(population) if stats else {}\n",
    "        logbook.record(gen=gen, **record)\n",
    "        if verbose:\n",
    "            print(logbook.stream)\n",
    "\n",
    "    return population, logbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Running the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \t      avg_fitness       \t      best_fitness      \t  connections  \t   hidden  \n",
      "   \t------------------------\t------------------------\t---------------\t-----------\n",
      "gen\tmin    \tavg    \tstd     \tmin    \tavg   \tstd     \tavg    \tstd    \tavg\tstd\n",
      "0  \t3.20063\t4.25901\t0.529687\t2.38362\t3.0483\t0.278345\t127.792\t10.5214\t0  \t0  \n",
      "1  \t3.1211 \t3.52496\t0.310917\t2.27684\t2.55651\t0.130452\t118.78 \t10.6604\t0.208\t0.405877\n",
      "2  \t3.01676\t3.40438\t0.33538 \t2.26767\t2.4417 \t0.0766381\t117.288\t6.8303 \t0.608\t0.649874\n",
      "3  \t2.9871 \t3.46817\t0.310269\t2.2516 \t2.37516\t0.0748565\t115.252\t7.92947\t1.568\t0.708079\n",
      "4  \t2.97715\t3.37534\t0.29308 \t2.21707\t2.39658\t0.057759 \t116.288\t7.89817\t2.408\t0.744   \n",
      "5  \t2.95145\t3.26687\t0.273054\t2.14717\t2.358  \t0.0978474\t118.444\t7.82808\t2.692\t0.914951\n",
      "6  \t2.89898\t3.30452\t0.217622\t2.11131\t2.30187\t0.112612 \t119.952\t9.08348\t3.592\t1.01663 \n",
      "7  \t2.86721\t3.1897 \t0.221555\t2.11939\t2.30278\t0.086225 \t121.916\t7.89816\t3.784\t0.988607\n",
      "8  \t2.89904\t3.18042\t0.202987\t2.17339\t2.29641\t0.0752939\t125.492\t6.70775\t4.564\t0.962239\n",
      "9  \t2.7843 \t3.17708\t0.240004\t2.09048\t2.2382 \t0.102606 \t122.208\t9.27129\t4.02 \t1.47635 \n",
      "10 \t2.79981\t3.13632\t0.212351\t2.07183\t2.25735\t0.0726832\t126.02 \t7.09448\t4.992\t1.59748 \n",
      "11 \t2.81207\t3.14956\t0.256079\t2.08358\t2.2217 \t0.086021 \t123.588\t8.97253\t4.352\t1.53496 \n",
      "12 \t2.77921\t3.20441\t0.263038\t2.007  \t2.16411\t0.105235 \t121.424\t9.61978\t4.076\t1.29546 \n",
      "13 \t2.7116 \t3.13414\t0.228039\t2.03805\t2.16623\t0.0536993\t127.152\t7.51005\t5.676\t1.76947 \n",
      "14 \t2.73119\t3.19567\t0.300924\t1.98078\t2.1788 \t0.0846175\t127.244\t8.16434\t5.788\t1.78635 \n",
      "15 \t2.7399 \t3.10316\t0.250308\t1.98861\t2.10126\t0.067608 \t127.684\t7.64828\t6.372\t1.89779 \n",
      "16 \t2.67072\t2.9503 \t0.227203\t1.97595\t2.1559 \t0.0800427\t132.764\t2.66314\t5.808\t1.84693 \n",
      "17 \t2.71856\t3.06429\t0.258523\t1.93296\t2.12975\t0.105361 \t130.604\t6.24429\t6.872\t1.90987 \n",
      "18 \t2.63948\t3.15169\t0.294268\t1.94221\t2.07472\t0.0997772\t127.84 \t8.69473\t6.88 \t1.70693 \n",
      "19 \t2.6582 \t2.98579\t0.315869\t1.98713\t2.12414\t0.0733054\t132.296\t6.41127\t7.388\t1.83234 \n",
      "20 \t2.66158\t3.02764\t0.304088\t1.95477\t2.13111\t0.104811 \t130.788\t8.84528\t7.156\t1.73311 \n",
      "21 \t2.60582\t3.08314\t0.301754\t1.98384\t2.09524\t0.0727477\t130.68 \t8.24582\t8.032\t1.85876 \n",
      "22 \t2.63755\t3.14713\t0.34904 \t1.91202\t2.09354\t0.100794 \t131.452\t7.67279\t7.944\t2.01317 \n",
      "23 \t2.61038\t3.03287\t0.333246\t1.88983\t2.03265\t0.0844718\t132.616\t7.53316\t8.632\t2.2469  \n",
      "24 \t2.58686\t2.96206\t0.275796\t1.87688\t2.11749\t0.0794959\t136.916\t2.84059\t9.264\t1.87678 \n",
      "25 \t2.54765\t3.01162\t0.382842\t1.86439\t2.06035\t0.105705 \t135.464\t6.77825\t9.26 \t1.97798 \n",
      "26 \t2.54132\t3.03515\t0.266882\t1.85958\t1.97979\t0.0746614\t135.516\t7.43248\t9.46 \t1.72754 \n",
      "27 \t2.57715\t3.11567\t0.267036\t1.90683\t1.98551\t0.0500253\t135.952\t7.94315\t10.036\t1.76031 \n",
      "28 \t2.57927\t2.91199\t0.367538\t1.90735\t2.05931\t0.0957012\t141.264\t2.33801\t9.976 \t1.50181 \n",
      "29 \t2.60615\t3.02397\t0.367705\t1.7924 \t1.91731\t0.0984537\t141.128\t2.44123\t10.348\t1.36927 \n",
      "30 \t2.53668\t2.86979\t0.273542\t1.8607 \t1.97064\t0.0650316\t142.216\t1.91033\t10.676\t1.43214 \n",
      "31 \t2.49977\t2.87462\t0.258461\t1.93764\t2.03209\t0.0551432\t142.828\t2.20871\t11.524\t1.69983 \n",
      "32 \t2.50536\t2.76351\t0.395678\t1.83108\t1.95146\t0.0939561\t144.708\t1.21603\t10.836\t2.07102 \n",
      "33 \t2.48721\t2.73318\t0.264646\t1.87724\t1.99137\t0.0571843\t145.368\t1.39448\t11.256\t2.34573 \n",
      "34 \t2.55777\t2.85935\t0.344833\t1.87501\t1.9916 \t0.090873 \t145.588\t1.68352\t12.192\t2.45339 \n",
      "35 \t2.53373\t2.72878\t0.36465 \t1.84713\t2.00685\t0.0936184\t146.884\t1.50948\t10.596\t2.19654 \n",
      "36 \t2.45254\t2.68601\t0.43759 \t1.79473\t1.96859\t0.0989361\t146.568\t1.46061\t10.304\t0.850637\n",
      "37 \t2.44142\t2.66652\t0.337556\t1.84309\t1.96455\t0.093083 \t147.612\t1.32267\t10.808\t1.7942  \n",
      "38 \t2.49718\t2.77415\t0.292917\t1.78958\t1.91703\t0.0629399\t147.496\t1.62788\t10.824\t1.26532 \n",
      "39 \t2.40946\t2.73994\t0.32305 \t1.78915\t1.90259\t0.0834951\t147.628\t1.37754\t12.696\t2.18988 \n",
      "40 \t2.46842\t2.83009\t0.428672\t1.82192\t1.94143\t0.0951749\t148.844\t1.12591\t12.936\t2.30215 \n",
      "41 \t2.50566\t2.85269\t0.324234\t1.78334\t1.85089\t0.0640338\t148.904\t1.10217\t13.476\t2.14136 \n",
      "42 \t2.42257\t2.73224\t0.377481\t1.80692\t1.94022\t0.090964 \t149.976\t1.43646\t12.472\t1.81141 \n",
      "43 \t2.45746\t2.80519\t0.217419\t1.81375\t1.89042\t0.0529824\t150.176\t1.43702\t13.536\t1.87422 \n",
      "44 \t2.42022\t2.69311\t0.433769\t1.76306\t1.91842\t0.106207 \t151.936\t1.56841\t12.18 \t1.46    \n",
      "45 \t2.4646 \t2.74123\t0.190774\t1.89636\t2.00491\t0.0567305\t152.28 \t1.48378\t13.132\t1.88324 \n",
      "46 \t2.44853\t2.66455\t0.341673\t1.77769\t1.89558\t0.0830941\t153.276\t1.30224\t12.216\t1.79146 \n",
      "47 \t2.42319\t2.63225\t0.335044\t1.74966\t1.91202\t0.0660513\t154.212\t1.29887\t12.204\t1.22408 \n",
      "48 \t2.42215\t2.69045\t0.255604\t1.7449 \t1.90021\t0.0912077\t154.192\t1.85557\t13.124\t2.22635 \n",
      "49 \t2.40417\t2.65848\t0.298598\t1.88997\t1.95406\t0.0499745\t154.428\t1.57633\t12.944\t1.24453 \n",
      "50 \t2.40791\t2.64513\t0.234441\t1.76061\t1.94953\t0.0714814\t156.704\t1.21671\t11.832\t0.977638\n",
      "51 \t2.40182\t2.61929\t0.388905\t1.75351\t1.88096\t0.0994214\t155.62 \t1.86644\t12.76 \t0.788923\n",
      "52 \t2.30657\t2.53568\t0.292855\t1.60364\t1.77108\t0.097721 \t155.828\t1.8885 \t13.444\t0.920252\n",
      "53 \t2.38492\t2.61348\t0.295489\t1.83947\t1.93318\t0.0690858\t156.656\t2.05564\t13.852\t0.991008\n",
      "54 \t2.3527 \t2.67571\t0.4147  \t1.79736\t1.87638\t0.0834995\t157.316\t1.97184\t14.28 \t1.16    \n",
      "55 \t2.35091\t2.64746\t0.350879\t1.73418\t1.83645\t0.077312 \t158.016\t1.86541\t14.896\t1.25107 \n",
      "56 \t2.30733\t2.51132\t0.289415\t1.68467\t1.82646\t0.0780316\t159.668\t2.27635\t14.744\t1.02687 \n",
      "57 \t2.32402\t2.54336\t0.256174\t1.72631\t1.83617\t0.0486429\t159.372\t2.27895\t15.12 \t1.32725 \n",
      "58 \t2.25585\t2.46125\t0.348944\t1.71108\t1.86794\t0.117274 \t161.092\t2.18255\t14.712\t1.03008 \n",
      "59 \t2.28682\t2.55357\t0.249264\t1.77128\t1.8705 \t0.0486726\t160.172\t2.56874\t15.44 \t1.30169 \n",
      "60 \t2.40985\t2.59176\t0.289972\t1.74735\t1.88893\t0.07849  \t162.276\t2.44782\t15.3  \t0.95184 \n",
      "61 \t2.28426\t2.46222\t0.170714\t1.55875\t1.77102\t0.087962 \t162.516\t3.09996\t15.728\t1.2546  \n",
      "62 \t2.27682\t2.50768\t0.231687\t1.6933 \t1.82637\t0.0546746\t162.656\t3.1051 \t15.972\t1.06734 \n",
      "63 \t2.22078\t2.53797\t0.501834\t1.72826\t1.82938\t0.114463 \t162.92 \t3.34329\t16.344\t1.20069 \n",
      "64 \t2.21358\t2.51174\t0.263093\t1.65362\t1.76387\t0.0488398\t163.948\t3.7727 \t16.776\t1.12686 \n",
      "65 \t2.19156\t2.40988\t0.43701 \t1.64452\t1.78577\t0.100278 \t166.168\t3.31719\t17.224\t1.01874 \n",
      "66 \t2.22938\t2.51092\t0.595537\t1.79848\t1.89657\t0.107253 \t166.224\t3.92401\t17.16 \t1.10562 \n",
      "67 \t2.18644\t2.44223\t0.354773\t1.71722\t1.84023\t0.0712055\t165.924\t4.76133\t18.092\t0.826762\n",
      "68 \t2.23024\t2.44428\t0.427158\t1.66686\t1.82631\t0.0958199\t169.02 \t3.59494\t17.796\t0.917815\n",
      "69 \t2.22194\t2.40551\t0.492927\t1.70553\t1.88469\t0.0969192\t170.02 \t2.53211\t18.32 \t0.567098\n",
      "70 \t2.18393\t2.45437\t0.354776\t1.57929\t1.74645\t0.126798 \t167.912\t3.28759\t18.676\t0.755661\n",
      "71 \t2.17498\t2.44325\t0.624364\t1.62247\t1.80454\t0.166139 \t169.736\t3.47596\t19.168\t0.944339\n",
      "72 \t2.2961 \t2.47049\t0.237283\t1.61519\t1.74097\t0.0783336\t168.156\t3.4577 \t19.144\t1.02921 \n",
      "73 \t2.11691\t2.40316\t0.433863\t1.57598\t1.69002\t0.0761639\t169.808\t3.17791\t18.888\t0.878326\n",
      "74 \t2.19109\t2.49696\t0.313633\t1.64407\t1.74057\t0.0761297\t168.124\t2.40429\t18.932\t0.838675\n",
      "75 \t2.24202\t2.40295\t0.180349\t1.6301 \t1.79624\t0.0842645\t170.764\t2.982  \t19.14 \t0.876584\n",
      "76 \t2.12547\t2.30076\t0.318151\t1.40608\t1.66293\t0.138007 \t171.4  \t3.0971 \t19.548\t0.769218\n",
      "77 \t2.09208\t2.31405\t0.197558\t1.52541\t1.63439\t0.0794519\t171.068\t3.61986\t19.488\t0.633921\n",
      "78 \t2.11684\t2.32682\t0.405236\t1.48594\t1.67663\t0.127106 \t173.548\t3.36091\t19.552\t0.747861\n",
      "79 \t2.14813\t2.31047\t0.30885 \t1.37668\t1.65407\t0.141112 \t173.884\t4.02275\t19.728\t0.702863\n",
      "80 \t2.12932\t2.36295\t0.413164\t1.65985\t1.75085\t0.0900966\t173.568\t4.5753 \t20.04 \t0.731027\n",
      "81 \t2.24668\t2.41318\t0.333267\t1.73607\t1.79699\t0.0414499\t176.3  \t3.25361\t20.256\t0.941522\n",
      "82 \t2.10259\t2.24103\t0.178995\t1.52567\t1.71361\t0.0692412\t178.132\t1.90015\t20.076\t0.937136\n",
      "83 \t2.12573\t2.39213\t0.542211\t1.48164\t1.6659 \t0.121923 \t177.84 \t3.04998\t20.036\t0.886963\n",
      "84 \t2.20698\t2.46929\t0.462496\t1.54323\t1.73697\t0.133379 \t176.74 \t2.92034\t20.204\t0.868553\n",
      "85 \t2.11144\t2.36626\t0.497056\t1.53496\t1.70649\t0.101361 \t178.152\t3.05825\t19.96 \t0.778717\n",
      "86 \t1.99004\t2.22347\t0.317647\t1.36428\t1.60503\t0.1456   \t179.116\t3.01704\t20.352\t0.660376\n",
      "87 \t2.10288\t2.35733\t0.186639\t1.61394\t1.73739\t0.0743846\t179.096\t3.09431\t20.592\t0.839962\n",
      "88 \t2.04944\t2.29918\t0.572687\t1.49741\t1.6419 \t0.143559 \t180.164\t3.01083\t20.896\t0.974261\n",
      "89 \t2.13213\t2.35898\t0.181908\t1.57439\t1.67733\t0.0668965\t180.18 \t3.39935\t21.288\t0.851502\n",
      "90 \t2.06232\t2.29226\t0.451271\t1.65307\t1.81386\t0.110949 \t183.748\t1.89644\t21.14 \t0.97591 \n",
      "91 \t1.96378\t2.18743\t0.346612\t1.31139\t1.5687 \t0.127409 \t183.528\t2.21297\t21.856\t0.887279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 \t2.08328\t2.28031\t0.166142\t1.44254\t1.64381\t0.0934067\t183.572\t2.26204\t22.236\t0.91886 \n",
      "93 \t2.04647\t2.24177\t0.219722\t1.56254\t1.68561\t0.0740485\t183.544\t2.15594\t22.808\t0.816784\n",
      "94 \t2.0017 \t2.24296\t0.364008\t1.50621\t1.65291\t0.131719 \t183.652\t2.1769 \t22.836\t0.795678\n",
      "95 \t2.00553\t2.23481\t0.257758\t1.38919\t1.58375\t0.110183 \t184.488\t2.27549\t23.088\t0.967603\n",
      "96 \t1.90886\t2.24602\t0.199281\t1.34248\t1.49971\t0.110612 \t184.468\t2.46759\t23.584\t1.04448 \n",
      "97 \t1.96312\t2.22615\t0.228906\t1.42677\t1.56574\t0.0977747\t184.224\t1.93231\t23.244\t0.681516\n",
      "98 \t1.97045\t2.28567\t0.646537\t1.65301\t1.73604\t0.0978543\t184.532\t2.11494\t23.368\t0.632911\n",
      "99 \t1.89157\t2.18661\t0.449118\t1.43368\t1.58947\t0.123501 \t185.94 \t2.35635\t23.692\t0.655085\n",
      "100\t1.85214\t2.24405\t0.359259\t1.47896\t1.59042\t0.096511 \t185.804\t1.71277\t23.78 \t0.628967\n",
      "101\t1.90353\t2.22794\t0.198092\t1.47445\t1.61607\t0.0903438\t185.324\t1.57322\t23.736\t0.665059\n",
      "102\t1.96653\t2.23644\t0.213139\t1.41782\t1.56603\t0.101848 \t186.92 \t1.38333\t24.04 \t0.793977\n",
      "103\t1.85666\t2.2214 \t0.31177 \t1.26506\t1.44972\t0.164987 \t186.992\t1.93286\t23.932\t0.774194\n",
      "104\t1.88527\t2.26342\t0.449464\t1.47621\t1.59526\t0.093155 \t188.532\t0.92573\t24.096\t0.631493\n",
      "105\t1.92168\t2.23343\t0.333875\t1.54443\t1.68755\t0.120496 \t189.012\t1.03723\t24.224\t0.685437\n",
      "106\t1.80551\t2.04301\t0.385865\t1.2538 \t1.47322\t0.117163 \t189.02 \t1.30981\t24.404\t0.872229\n",
      "107\t1.80411\t2.13487\t0.293276\t1.43005\t1.58735\t0.120896 \t190.008\t1.15583\t25.02 \t0.887468\n",
      "108\t1.89182\t2.10977\t0.358834\t1.4001 \t1.59833\t0.132549 \t190.936\t0.944407\t25.496\t0.835454\n",
      "109\t1.84645\t2.23347\t0.194255\t1.39966\t1.51859\t0.102622 \t191.524\t1.17022 \t26.004\t0.957071\n",
      "110\t1.85699\t2.18179\t0.183578\t1.40026\t1.50542\t0.123211 \t192.552\t1.58471 \t26.336\t1.25184 \n",
      "111\t1.8279 \t2.23578\t0.408741\t1.46752\t1.58241\t0.141443 \t192.564\t1.78827 \t26.26 \t1.12801 \n",
      "112\t1.74074\t2.04773\t0.252148\t1.23774\t1.39014\t0.137838 \t192.312\t1.61699 \t26.244\t1.23307 \n",
      "113\t1.86778\t2.12211\t0.19195 \t1.59874\t1.68937\t0.0582401\t192.304\t1.8835  \t26.188\t1.25883 \n",
      "114\t1.79543\t2.06323\t0.45816 \t1.16013\t1.41543\t0.178616 \t192.924\t1.14465 \t26.972\t0.887252\n",
      "115\t1.83061\t2.20265\t0.273818\t1.41986\t1.54505\t0.108224 \t193.784\t1.08505 \t27.084\t0.888225\n",
      "116\t1.77966\t2.10429\t0.180716\t1.32413\t1.48088\t0.108953 \t194.144\t1.01748 \t27.652\t0.771295\n",
      "117\t1.71872\t2.06394\t0.375413\t1.23391\t1.43464\t0.142702 \t194.82 \t1.41266 \t28.068\t0.958841\n",
      "118\t1.83382\t2.11568\t0.477778\t1.4965 \t1.63337\t0.113104 \t195.3  \t1.6081  \t28.184\t0.911122\n",
      "119\t1.93507\t2.19073\t0.380976\t1.43009\t1.60578\t0.11995  \t195.092\t2.79634 \t27.692\t1.40468 \n",
      "120\t1.85312\t2.24487\t0.520958\t1.55192\t1.65065\t0.164531 \t196.044\t1.36017 \t28.344\t0.749442\n",
      "121\t1.79394\t2.10075\t0.498802\t1.43844\t1.60419\t0.112363 \t196.032\t2.02163 \t27.856\t0.98146 \n",
      "122\t1.68904\t2.03267\t0.417067\t1.23446\t1.41151\t0.135544 \t195.2  \t2.56905 \t27.576\t1.18837 \n",
      "123\t1.85544\t2.25762\t0.437312\t1.51722\t1.64676\t0.114699 \t197.04 \t1.83259 \t28.58 \t0.918477\n",
      "124\t1.77735\t2.00441\t0.413862\t1.28325\t1.55636\t0.12079  \t196.704\t2.45283 \t28.164\t1.30886 \n",
      "125\t1.79165\t2.03589\t0.304119\t1.44776\t1.5971 \t0.0943988\t198.056\t2.18652 \t29.168\t1.15055 \n",
      "126\t1.82174\t2.10256\t0.232585\t1.37443\t1.60191\t0.103593 \t199.152\t2.65347 \t28.852\t1.22233 \n",
      "127\t1.81817\t2.13719\t0.32356 \t1.47819\t1.5881 \t0.0842068\t198.512\t2.32074 \t29.428\t1.41874 \n",
      "128\t1.7953 \t2.08807\t0.26778 \t1.34173\t1.51401\t0.124794 \t199.712\t2.5778  \t29.324\t1.21779 \n",
      "129\t1.85978\t2.15873\t0.310502\t1.34653\t1.51113\t0.120401 \t200.656\t2.18944 \t30.324\t0.864306\n",
      "130\t1.77413\t2.06039\t0.629832\t1.35764\t1.49969\t0.12236  \t200.412\t1.85533 \t30.252\t1.10838 \n",
      "131\t1.7745 \t1.99227\t0.412798\t1.37636\t1.55174\t0.112914 \t200.704\t1.59511 \t30.66 \t0.996193\n",
      "132\t1.80161\t2.03296\t0.385123\t1.30753\t1.49734\t0.134254 \t201.28 \t1.902   \t30.528\t0.73295 \n",
      "133\t1.79679\t2.06079\t0.358745\t1.3634 \t1.56102\t0.129757 \t201.772\t2.1429  \t30.644\t0.851624\n",
      "134\t1.85318\t2.08948\t0.363936\t1.4685 \t1.65172\t0.102144 \t202.352\t2.05039 \t30.968\t0.898318\n",
      "135\t1.73459\t2.03476\t0.454727\t1.34255\t1.54767\t0.117754 \t203.532\t1.70205 \t30.744\t1.08373 \n",
      "136\t1.88229\t2.11721\t0.269591\t1.47685\t1.62889\t0.0962069\t204.02 \t2.53685 \t31.248\t1.12894 \n",
      "137\t1.76972\t2.00349\t0.214477\t1.39218\t1.58099\t0.103049 \t204.392\t1.82382 \t30.484\t0.73331 \n",
      "138\t1.803  \t2.0641 \t0.539333\t1.3566 \t1.50122\t0.124264 \t202.86 \t2.58465 \t31.28 \t1.14961 \n",
      "139\t1.74004\t1.94964\t0.327459\t1.37208\t1.53837\t0.103234 \t203.752\t2.83311 \t31.236\t1.09741 \n",
      "140\t1.78393\t2.02565\t0.19554 \t1.31171\t1.52813\t0.136743 \t205.524\t3.42599 \t32.156\t1.5886  \n",
      "141\t1.70314\t1.93179\t0.369291\t1.3073 \t1.42518\t0.109887 \t203.9  \t2.69555 \t32.372\t1.21063 \n",
      "142\t1.76406\t1.93915\t0.19075 \t1.28586\t1.48322\t0.111004 \t206.156\t3.20432 \t32.276\t1.6124  \n",
      "143\t1.80706\t2.11729\t0.341633\t1.43782\t1.58553\t0.11981  \t208.088\t3.04766 \t33.64 \t2.19053 \n",
      "144\t1.73491\t1.98009\t0.362979\t1.33805\t1.50261\t0.116792 \t206.584\t2.95888 \t32.624\t2.2205  \n",
      "145\t1.74821\t2.04844\t0.329185\t1.37214\t1.49505\t0.103769 \t208.152\t2.97605 \t33.212\t2.06278 \n",
      "146\t1.78551\t2.09627\t0.38871 \t1.47649\t1.56735\t0.0853861\t209.048\t2.87014 \t34.244\t1.70425 \n",
      "147\t1.7492 \t1.98078\t0.36929 \t1.36231\t1.48963\t0.111768 \t207.968\t3.65937 \t33.38 \t1.77415 \n",
      "148\t1.80412\t1.99526\t0.281928\t1.54737\t1.6718 \t0.0704235\t208.48 \t3.27683 \t32.784\t1.9456  \n",
      "149\t1.84249\t2.08198\t0.579426\t1.54511\t1.65457\t0.0853392\t207.448\t2.59062 \t33.408\t2.28944 \n",
      "150\t1.71321\t1.91792\t0.360095\t1.35037\t1.49598\t0.0999937\t207.988\t2.37905 \t34.068\t2.59372 \n",
      "151\t1.81063\t2.01333\t0.289391\t1.56391\t1.62731\t0.0394121\t208.752\t2.35    \t34.5  \t2.64613 \n",
      "152\t1.87167\t2.04933\t0.349785\t1.43789\t1.56928\t0.0942955\t209.088\t2.32729 \t34.588\t2.63406 \n",
      "153\t1.70629\t1.91566\t0.386021\t1.41027\t1.55895\t0.106118 \t210.668\t1.97327 \t35.252\t3.67103 \n",
      "154\t1.76941\t1.95189\t0.280848\t1.42683\t1.58389\t0.123538 \t211.484\t2.12644 \t34.708\t3.60316 \n",
      "155\t1.65836\t1.82886\t0.240299\t1.24889\t1.40382\t0.11238  \t212.004\t1.93804 \t34.356\t3.75836 \n",
      "156\t1.75252\t2.00757\t0.358279\t1.48239\t1.57699\t0.0911775\t211.016\t1.83296 \t36.312\t3.21102 \n",
      "157\t1.66194\t1.8544 \t0.220596\t1.34313\t1.49761\t0.114484 \t212.292\t1.77278 \t35.708\t3.45698 \n",
      "158\t1.63168\t1.85756\t0.479886\t1.3363 \t1.4598 \t0.120752 \t212.732\t1.72168 \t33.788\t3.43031 \n",
      "159\t1.76372\t1.97111\t0.288364\t1.47583\t1.57654\t0.0706242\t213.484\t1.9884  \t33.82 \t3.33281 \n",
      "160\t1.75122\t1.9214 \t0.291654\t1.45306\t1.57756\t0.0757599\t214.136\t1.95077 \t34.416\t3.55119 \n",
      "161\t1.68164\t1.83621\t0.271974\t1.27736\t1.48582\t0.0952164\t215.536\t1.79575 \t32.728\t2.87576 \n",
      "162\t1.50099\t1.70997\t0.275095\t1.1351 \t1.27433\t0.117321 \t214.568\t2.01131 \t35.384\t3.77207 \n",
      "163\t1.76379\t1.97607\t0.481785\t1.44432\t1.57818\t0.111417 \t215.044\t1.71641 \t37.368\t3.35627 \n",
      "164\t1.81217\t1.99231\t0.478094\t1.5377 \t1.60409\t0.0921777\t216.14 \t1.26507 \t34.252\t3.53334 \n",
      "165\t1.63115\t1.78787\t0.286168\t1.42047\t1.49649\t0.0677377\t217.472\t0.825358\t31.668\t0.667665\n",
      "166\t1.64568\t1.81406\t0.325634\t1.33202\t1.49596\t0.0706475\t217.16 \t0.897998\t31.544\t0.619729\n",
      "167\t1.61598\t1.82158\t0.420029\t1.3764 \t1.49961\t0.0920074\t217.268\t0.887793\t31.576\t0.642047\n",
      "168\t1.65801\t2.13139\t0.582355\t1.34202\t1.45207\t0.0925706\t218.004\t0.740259\t31.836\t0.732874\n",
      "169\t1.81042\t2.08766\t0.404872\t1.63236\t1.70621\t0.0572592\t218.216\t0.912877\t31.688\t0.714602\n",
      "170\t1.58519\t1.87582\t0.597497\t1.3767 \t1.534  \t0.104035 \t218.284\t0.826646\t31.752\t0.711685\n",
      "171\t1.65329\t1.8082 \t0.317123\t1.43206\t1.5516 \t0.0703287\t218.812\t0.805392\t31.628\t0.658495\n",
      "172\t1.54567\t1.70253\t0.347722\t1.2078 \t1.32835\t0.141619 \t219.36 \t0.80895 \t31.744\t0.708847\n",
      "173\t1.66112\t1.81392\t0.372044\t1.3606 \t1.45338\t0.078384 \t219.868\t0.977024\t32.112\t0.956795\n",
      "174\t1.54769\t1.77395\t0.511723\t1.12184\t1.23307\t0.144664 \t220.324\t1.00947 \t32.156\t0.965227\n",
      "175\t1.58869\t1.73698\t0.380272\t1.20062\t1.31432\t0.126444 \t221.008\t1.19329 \t32.692\t0.957672\n",
      "176\t1.61574\t1.75478\t0.213783\t1.30869\t1.41981\t0.0825877\t221.908\t1.09706 \t32.94 \t0.925419\n",
      "177\t1.7128 \t1.91184\t0.289406\t1.42883\t1.51533\t0.079409 \t221.996\t1.2149  \t32.632\t0.681598\n",
      "178\t1.67283\t1.85116\t0.369513\t1.3217 \t1.4327 \t0.0871475\t222.832\t1.41837 \t32.884\t0.725634\n",
      "179\t1.73826\t1.92389\t0.486301\t1.45081\t1.53275\t0.0958633\t222.924\t1.18921 \t32.696\t0.750722\n",
      "180\t1.66068\t1.84291\t0.517157\t1.41362\t1.50991\t0.102898 \t222.764\t1.1884  \t32.828\t0.637508\n",
      "181\t1.64453\t1.83385\t0.447513\t1.38856\t1.47307\t0.105882 \t224.124\t1.26041 \t33.18 \t0.568859\n",
      "182\t1.58819\t1.74092\t0.308676\t1.29206\t1.43294\t0.0946012\t225.116\t1.32911 \t33.428\t0.65484 \n",
      "183\t1.76656\t1.89178\t0.214527\t1.41894\t1.50922\t0.0587286\t225.92 \t1.64    \t34.164\t0.849178\n",
      "184\t1.56441\t1.6978 \t0.259324\t1.2439 \t1.3691 \t0.120676 \t227.088\t1.9412  \t34.56 \t0.80399 \n",
      "185\t1.65869\t1.8482 \t0.455406\t1.48274\t1.54958\t0.0762952\t227.372\t1.76907 \t34.6  \t0.794984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186\t1.56881\t1.73692\t0.357015\t1.24218\t1.34666\t0.102036 \t227.408\t2.14325 \t34.688\t0.945863\n",
      "187\t1.62067\t1.85282\t0.576574\t1.22709\t1.36182\t0.135548 \t228.292\t2.22323 \t34.66 \t1.37419 \n",
      "188\t1.50844\t1.78062\t0.499651\t1.17326\t1.30463\t0.118223 \t229.756\t2.41008 \t35.668\t1.92192 \n",
      "189\t1.62753\t1.78482\t0.320235\t1.40905\t1.49535\t0.0738453\t230.04 \t2.47677 \t35.756\t2.09773 \n",
      "190\t1.55907\t1.69541\t0.261254\t1.34332\t1.43397\t0.0809894\t233.4  \t1.58997 \t38.112\t1.32191 \n",
      "191\t1.6258 \t1.77743\t0.3989  \t1.35893\t1.46313\t0.0727915\t233.716\t1.82739 \t37.968\t1.66823 \n",
      "192\t1.57612\t1.73372\t0.238283\t1.22779\t1.35545\t0.112153 \t234.62 \t1.06752 \t38.872\t0.758694\n",
      "193\t1.54766\t1.6695 \t0.288312\t1.27844\t1.39814\t0.0889206\t235.328\t0.914558\t39.352\t0.596738\n",
      "194\t1.6005 \t1.73394\t0.352963\t1.13224\t1.29867\t0.11072  \t235.728\t0.768125\t39.292\t0.471949\n",
      "195\t1.55965\t1.6589 \t0.258045\t1.23725\t1.36301\t0.0961304\t236.22 \t1.08977 \t39.784\t0.658289\n",
      "196\t1.49872\t1.64872\t0.265866\t1.21653\t1.33153\t0.124781 \t236.2  \t0.774597\t40.036\t0.683157\n",
      "197\t1.53301\t1.65659\t0.37467 \t1.28287\t1.39677\t0.105152 \t237.244\t1.14213 \t40.328\t0.96975 \n",
      "198\t1.73197\t1.90377\t0.65621 \t1.53251\t1.6031 \t0.0950967\t237.736\t0.826017\t41.264\t1.33952 \n",
      "199\t1.63041\t1.77888\t0.317102\t1.48029\t1.54243\t0.0632334\t238.024\t0.78449 \t40    \t0.907744\n",
      "200\t1.58198\t1.76323\t0.410659\t1.26468\t1.41839\t0.117382 \t238.604\t1.04651 \t40.18 \t0.944246\n",
      "201\t1.51663\t1.64225\t0.219449\t1.13637\t1.21458\t0.0867166\t238.5  \t0.960208\t40.264\t0.952   \n",
      "202\t1.59663\t1.73489\t0.263467\t1.32643\t1.44264\t0.0840565\t239.572\t1.00241 \t41.376\t0.765914\n",
      "203\t1.54921\t1.70606\t0.261864\t1.18927\t1.30539\t0.095433 \t239.3  \t1.22719 \t41.284\t0.712281\n",
      "204\t1.67111\t1.79853\t0.31454 \t1.418  \t1.49208\t0.0386007\t240.208\t1.52208 \t41.328\t0.832115\n",
      "205\t1.49954\t1.75346\t0.316296\t1.17202\t1.30964\t0.0849462\t241.196\t1.61666 \t41.528\t0.759747\n",
      "206\t1.50578\t1.58904\t0.164101\t1.20644\t1.30236\t0.0746099\t242    \t1.62481 \t41.576\t0.910068\n",
      "207\t1.53911\t1.67571\t0.377427\t1.2493 \t1.36521\t0.0901515\t241.452\t1.94723 \t41.644\t1.17527 \n",
      "208\t1.58003\t1.69659\t0.269847\t1.35947\t1.45476\t0.068823 \t242.22 \t1.73078 \t41.6  \t0.987927\n",
      "209\t1.5403 \t1.65433\t0.21788 \t1.2068 \t1.30743\t0.0860827\t242.78 \t1.88987 \t41.84 \t1.17576 \n",
      "210\t1.53499\t1.63221\t0.19577 \t1.26032\t1.39852\t0.0606653\t242.42 \t2.1697  \t41.608\t1.32602 \n",
      "211\t1.57211\t1.69939\t0.326909\t1.33406\t1.42369\t0.0547807\t243.516\t1.81156 \t42.024\t1.2804  \n",
      "212\t1.49124\t1.69902\t0.422696\t1.17639\t1.28356\t0.0878755\t243.764\t1.68651 \t42.476\t1.24315 \n",
      "213\t1.58469\t1.7272 \t0.341659\t1.40563\t1.5022 \t0.0561171\t244.904\t1.72939 \t42.86 \t1.33581 \n",
      "214\t1.47886\t1.70794\t0.362102\t1.15536\t1.29107\t0.114581 \t243.88 \t1.88934 \t42.268\t1.3521  \n",
      "215\t1.45837\t1.59108\t0.292163\t1.196  \t1.30844\t0.0748203\t245.516\t1.89149 \t42.944\t1.8732  \n",
      "216\t1.53845\t1.70583\t0.423073\t1.27059\t1.37898\t0.105102 \t245.76 \t1.3937  \t42.252\t1.522   \n",
      "217\t1.5993 \t1.74858\t0.292106\t1.30032\t1.43969\t0.0800449\t245.924\t2.56714 \t43.284\t2.26348 \n",
      "218\t1.51474\t1.7442 \t0.529789\t1.14994\t1.29525\t0.13627  \t245.832\t2.05226 \t42.336\t1.77062 \n",
      "219\t1.49703\t1.69801\t0.343708\t1.21059\t1.33133\t0.0836252\t246.944\t2.27966 \t42.808\t1.9024  \n",
      "220\t1.57193\t1.67041\t0.198912\t1.27309\t1.35311\t0.0757818\t247.64 \t2.06068 \t42.852\t1.93652 \n",
      "221\t1.53471\t1.64169\t0.248535\t1.15104\t1.29017\t0.0702935\t246.516\t1.86809 \t42.672\t1.01805 \n",
      "222\t1.46623\t1.63212\t0.284304\t1.17027\t1.28267\t0.116857 \t247.848\t2.16723 \t43.412\t1.73039 \n",
      "223\t1.49604\t1.66769\t0.522763\t1.05739\t1.21042\t0.120298 \t248.24 \t1.90955 \t43.636\t1.42811 \n",
      "224\t1.56027\t1.67558\t0.333994\t1.22104\t1.41574\t0.0798886\t248.448\t2.63653 \t44.556\t2.30453 \n",
      "225\t1.56357\t1.76189\t0.458625\t1.11389\t1.28341\t0.0979129\t247.372\t1.46479 \t42.424\t0.944576\n",
      "226\t1.55725\t2.13048\t0.661453\t1.05222\t1.14484\t0.101159 \t249.12 \t1.37463 \t42.28 \t0.722219\n",
      "227\t1.63225\t1.78443\t0.396922\t1.25553\t1.40252\t0.0631251\t249.088\t1.48063 \t42.672\t0.792727\n",
      "228\t1.43944\t1.62025\t0.278596\t0.975936\t1.05339\t0.107647 \t250    \t1.71114 \t42.672\t0.718621\n",
      "229\t1.46709\t1.63239\t0.437357\t1.08665 \t1.20559\t0.125873 \t248.924\t1.81279 \t42.732\t0.756423\n",
      "230\t1.56772\t1.72519\t0.358143\t1.30121 \t1.3888 \t0.0458506\t249.44 \t1.77719 \t43.064\t0.892135\n",
      "231\t1.61278\t1.73919\t0.22235 \t1.2178  \t1.33862\t0.102217 \t249.452\t1.94517 \t43.264\t1.06316 \n",
      "232\t1.57932\t1.72492\t0.298946\t1.23959 \t1.37911\t0.0928629\t251.328\t2.73577 \t44.24 \t1.12357 \n",
      "233\t1.54991\t1.68602\t0.294409\t1.15684 \t1.24494\t0.107196 \t252.424\t2.41748 \t44.448\t1.23907 \n",
      "234\t1.56085\t1.66881\t0.238603\t1.23882 \t1.36801\t0.090237 \t251.4  \t3.205   \t44.268\t1.21827 \n",
      "235\t1.41843\t1.52677\t0.249421\t0.970677\t1.03949\t0.11255  \t255.336\t1.16237 \t46.108\t0.885627\n",
      "236\t1.58806\t1.7233 \t0.271007\t1.28532 \t1.36663\t0.0642247\t255.36 \t2.07808 \t45.972\t1.06359 \n",
      "237\t1.62935\t1.72392\t0.330436\t1.33389 \t1.41808\t0.0682343\t253.852\t3.5964  \t45.48 \t1.56512 \n",
      "238\t1.60821\t1.71434\t0.229479\t1.21692 \t1.3458 \t0.0918366\t254.744\t3.2085  \t46.012\t1.70759 \n",
      "239\t1.54485\t1.68345\t0.206983\t1.25339 \t1.3582 \t0.0758978\t256.752\t1.14302 \t47.264\t0.705907\n"
     ]
    }
   ],
   "source": [
    "# Run the evolutionary algorithm\n",
    "pop = toolbox.population(POPULATION_SIZE)\n",
    "hof = tools.HallOfFame(10)\n",
    "pop, log = eaWann(population=pop, toolbox=toolbox, ngen=N_GENERATIONS, cull_ratio=CULL_RATIO, \n",
    "                  elite_ratio=ELITE_RATIO, stats=mstats, halloffame=hof, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Wrapping up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results\n",
    "with open(RESULTS_FILENAME, \"wb\") as f:\n",
    "    pickle.dump((pop, log, hof), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract generation IDs, minimum fitnesses and average total heights per generation\n",
    "gen = log.select(\"gen\")\n",
    "fitness_best = log.chapters[\"avg_fitness\"].select(\"min\") \n",
    "conn_avg = log.chapters[\"connections\"].select(\"avg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot line for minimum fitness\n",
    "fig, fit_ax = plt.subplots()\n",
    "fit_line = fit_ax.plot(gen, fitness_best, \"b-\", label=\"Best Fitness\")\n",
    "fit_ax.set_xlabel(\"Generation\")\n",
    "fit_ax.set_ylabel(f\"Cross-entropy Loss\", color=\"b\")\n",
    "for tl in fit_ax.get_yticklabels():\n",
    "    tl.set_color(\"b\")\n",
    "\n",
    "# Plot line for average total height\n",
    "height_ax = fit_ax.twinx()\n",
    "height_line = height_ax.plot(gen, conn_avg, \"r-\", label=\"Average Number of Connections\")\n",
    "height_ax.set_ylabel(\"# Connections\", color=\"r\")\n",
    "for tl in height_ax.get_yticklabels():\n",
    "    tl.set_color(\"r\")\n",
    "\n",
    "# Add legend\n",
    "lines = fit_line + height_line\n",
    "labs = [l.get_label() for l in lines]\n",
    "fit_ax.legend(lines, labs, bbox_to_anchor=(0.8, -0.15))\n",
    "\n",
    "# Show the result\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the best individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ind = hof[0]\n",
    "print(best_ind)\n",
    "print(f\"Fitness of best individual: {best_ind.fitness}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Printing trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the trees of the best individual\n",
    "for string in best_ind.get_strings():\n",
    "    print(f\"{string}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Computing training & validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving predictions from an individual\n",
    "def get_predictions(individual, X, weight):\n",
    "    func = compile_multiclasstree(individual)\n",
    "    predictions = []\n",
    "    for i in range(X.shape[0]):\n",
    "        outputs_i = func(weight, X[i])\n",
    "        predictions.append(np.argmax(outputs_i))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute accuracy of predictions\n",
    "def compute_accuracy(Y_pred, Y_true):\n",
    "    n_correct = np.sum(Y_pred == Y_true)\n",
    "    return n_correct/Y_true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve predictions of the best individual on the training and validation sets, for all weights\n",
    "Y_train_pred = np.array([get_predictions(best_ind, X_train, w) for w in WEIGHTS_TO_TEST])\n",
    "Y_test_pred = np.array([get_predictions(best_ind, X_test, w) for w in WEIGHTS_TO_TEST])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute training accuracies for all weights and extract the best weight\n",
    "train_accs = [compute_accuracy(Y_train_pred[i], Y_train) for i in range(len(WEIGHTS_TO_TEST))]\n",
    "test_accs = [compute_accuracy(Y_test_pred[i], Y_test) for i in range(len(WEIGHTS_TO_TEST))]\n",
    "best_weight_idx_train = np.argmax(train_accs)\n",
    "best_weight_idx_test = np.argmax(test_accs)\n",
    "\n",
    "# Print best training and validation accuracies of the best individual\n",
    "print(f\"Best training accuracy (weight {WEIGHTS_TO_TEST[best_weight_idx_train]}): {np.max(train_accs)}\")\n",
    "print(f\"Best validation accuracy (weight {WEIGHTS_TO_TEST[best_weight_idx_test]}): {np.max(test_accs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain majority votes (in case of a tie, use vote of the best classifier)\n",
    "def get_majority_predictions(predictions):\n",
    "    def _majority(l):\n",
    "        return max(set(l), key=l.count)\n",
    "    predictions = [_majority(list(predictions[:,i])) for i in range(predictions.shape[1])]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute majority predictions for train and validation sets\n",
    "Y_train_majpred = get_majority_predictions(Y_train_pred)\n",
    "Y_test_majpred = get_majority_predictions(Y_test_pred)\n",
    "\n",
    "# Print the accuracies of the majority votes\n",
    "print(f\"Majority training accuracy: {compute_accuracy(Y_train_majpred, Y_train)}\")\n",
    "print(f\"Majority validation accuracy: {compute_accuracy(Y_test_majpred, Y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrices\n",
    "cm_train_best = confusion_matrix(Y_train, Y_train_pred[best_weight_idx_train], labels=range(N_CLASSES_TO_USE))\n",
    "cm_test_best = confusion_matrix(Y_test, Y_test_pred[best_weight_idx_test], labels=range(N_CLASSES_TO_USE))\n",
    "cm_train_maj = confusion_matrix(Y_train, Y_train_majpred, labels=range(N_CLASSES_TO_USE))\n",
    "cm_test_maj = confusion_matrix(Y_test, Y_test_majpred, labels=range(N_CLASSES_TO_USE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure\n",
    "fig, ax = plt.subplots(2,2, figsize=(11,10))\n",
    "ax = ax.ravel()\n",
    "\n",
    "# Plot confusion matrix for training data using best weight\n",
    "sns.heatmap(cm_train_best, annot=True, fmt='g', ax=ax[0], cmap=\"Blues\")\n",
    "ax[0].set_xlabel('Predicted labels')\n",
    "ax[0].set_ylabel('True labels')\n",
    "ax[0].set_title('Confusion matrix for training data (best weight)')\n",
    "\n",
    "# Plot confusion matrix for validation data using best weight\n",
    "sns.heatmap(cm_test_best, annot=True, fmt='g', ax=ax[1], cmap=\"Blues\")\n",
    "ax[1].set_xlabel('Predicted labels')\n",
    "ax[1].set_ylabel('True labels')\n",
    "ax[1].set_title('Confusion matrix for validation data (best weight)')\n",
    "\n",
    "# Plot confusion matrix for training data using majority vote\n",
    "sns.heatmap(cm_train_maj, annot=True, fmt='g', ax=ax[2], cmap=\"Blues\")\n",
    "ax[2].set_xlabel('Predicted labels')\n",
    "ax[2].set_ylabel('True labels')\n",
    "ax[2].set_title('Confusion matrix for training data (majority vote)')\n",
    "\n",
    "# Plot confusion matrix for validation data using majority vote\n",
    "sns.heatmap(cm_test_maj, annot=True, fmt='g', ax=ax[3], cmap=\"Blues\")\n",
    "ax[3].set_xlabel('Predicted labels')\n",
    "ax[3].set_ylabel('True labels')\n",
    "ax[3].set_title('Confusion matrix for validation data (majority vote)')\n",
    "\n",
    "# Show the result\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Used features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract input tallies from best individual\n",
    "input_tallies = []\n",
    "for tree in best_ind.get_strings():\n",
    "    inputs_used = list(map(int, re.findall(\"[0-9]+\", tree)))\n",
    "    input_tally = np.zeros(X_train.shape[1])\n",
    "    for arg in inputs_used:\n",
    "        input_tally[arg] += 1\n",
    "    input_tallies.append(input_tally)\n",
    "\n",
    "# Create plots of the inputs (pixels) used in the tree of the best individual for each class\n",
    "# Note: for the best-looking plot, this implementation assumes that N_CLASSES_TO_USE is set to 10\n",
    "fig, ax = plt.subplots(2, 5, figsize=(16,5))\n",
    "ax = ax.ravel()\n",
    "for i, tally in enumerate(input_tallies):\n",
    "    img_shape = int(math.sqrt(X_train.shape[1]))\n",
    "    ax[i].imshow(np.array(tally).reshape(img_shape, img_shape), clim=(0,np.max(input_tallies)))\n",
    "    ax[i].axis(\"off\")\n",
    "    ax[i].set_title(f\"Pixels used for class {i}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot image of all inputs used in the tree\n",
    "plt.imshow(np.sum(input_tallies, axis=0).reshape(16,16))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Pixels used in the entire tree\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

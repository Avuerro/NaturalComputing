{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Computing - Project\n",
    "#### Submission by group 25 (Chihab Amghane, Max Driessen, Jordy Naus)\n",
    "\n",
    "The code below uses the DEAP framework (https://github.com/deap/deap), which is a very intuitive framework for evolutionary algorithms and genetic programming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEAP\n",
    "from deap import gp, base, tools, creator, algorithms\n",
    "\n",
    "# Data processing and plotting\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Requirements for the algorithm\n",
    "from operator import attrgetter\n",
    "from functools import partial\n",
    "\n",
    "# Standard python imports\n",
    "import random, pickle, math, re, os\n",
    "import numpy as np\n",
    "\n",
    "# Magic for inline plots\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp(x):\n",
    "    return np.exp(np.clip(x, -float('inf'), 709.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_height(individual):\n",
    "    return sum([tree.height for tree in individual])/len(individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trees(individual):\n",
    "    for tree in individual:\n",
    "        print(f\"{tree}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset parameters\n",
    "DATASET = \"Fashion-MNIST\" # choose from {\"MNIST\", \"Fashion-MNIST\"} \n",
    "N_CLASSES_TO_USE = 10 # at most 10\n",
    "\n",
    "# Individual tree parameters\n",
    "MAX_ARITY = 10\n",
    "MIN_INITIAL_HEIGHT = 3\n",
    "MAX_INITIAL_HEIGHT = 5\n",
    "\n",
    "HEIGHT_CAPPED = True\n",
    "MAX_AVG_HEIGHT = 20\n",
    "\n",
    "# Fitness parameters\n",
    "SAMPLE_SIZE = 100\n",
    "\n",
    "# Evolution parameters\n",
    "N_GENERATIONS = 1000\n",
    "POPULATION_SIZE = 100\n",
    "\n",
    "TOURNAMENT_SIZE = 32\n",
    "SIZE_TOURNAMENT = True\n",
    "P_SMALLER_WINS = 0.65\n",
    "\n",
    "P_CROSSOVER = 1.0\n",
    "P_CROSSOVER_PER_TREE = 1.0\n",
    "\n",
    "P_MUTATION = 0.3\n",
    "P_MUTATION_PER_TREE = 0.2\n",
    "MIN_MUTATION_HEIGHT = 1\n",
    "MAX_MUTATION_HEIGHT = 3\n",
    "\n",
    "# Filename parameters\n",
    "RESULTS_FILENAME = f\"DEAP-{DATASET}-results.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the correct data filename\n",
    "filename = f\"{DATASET}-{N_CLASSES_TO_USE}.pkl\"\n",
    "\n",
    "# If the data has not yet been preprocessed in the specified way, do so now\n",
    "if not os.path.exists(os.path.join(\"data\", filename)):\n",
    "    print(\"Preprocessed dataset does not exist yet, creating now.\")\n",
    "    os.system(f\"python Preprocessing.py -d {DATASET} -c {N_CLASSES_TO_USE}\")\n",
    "\n",
    "# Load the preprocessed data\n",
    "with open(os.path.join(\"data\", filename), \"rb\") as f:\n",
    "    (X_train, Y_train), (X_test, Y_test) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create set of functions and terminals, with one terminal for each pixel\n",
    "pset = gp.PrimitiveSet(\"main\", X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define operators (with a variable number of inputs)\n",
    "def linear(*args):\n",
    "    return sum(args)\n",
    "\n",
    "def step(*args):\n",
    "    return float(sum(args) > 0)\n",
    "\n",
    "def sine(*args):\n",
    "    return np.sin(np.pi*sum(args))\n",
    "\n",
    "def gaussian(*args):\n",
    "    return exp(-np.multiply(sum(args), sum(args))/2.0)\n",
    "\n",
    "def tanh(*args):\n",
    "    return np.tanh(sum(args))\n",
    "\n",
    "def sigmoid(*args):\n",
    "    return (np.tanh(sum(args)/2.0) + 1.0)/2.0\n",
    "\n",
    "def inverse(*args):\n",
    "    return -sum(args)\n",
    "\n",
    "def absolute(*args):\n",
    "    return abs(sum(args))\n",
    "\n",
    "def relu(*args):\n",
    "    return np.maximum(0.0, sum(args))\n",
    "\n",
    "def cosine(*args):\n",
    "    return np.cos(np.pi*sum(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add operators to the set (using a \"hacky\" solution to allow variable arities)\n",
    "for arity in range(1, MAX_ARITY+1):\n",
    "    pset.addPrimitive(linear, arity)\n",
    "    pset.addPrimitive(step, arity)\n",
    "    pset.addPrimitive(sine, arity)\n",
    "    pset.addPrimitive(gaussian, arity)\n",
    "    pset.addPrimitive(tanh, arity)\n",
    "    pset.addPrimitive(sigmoid, arity)\n",
    "    pset.addPrimitive(inverse, arity)\n",
    "    pset.addPrimitive(absolute, arity)\n",
    "    pset.addPrimitive(relu, arity)\n",
    "    pset.addPrimitive(cosine, arity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialize the toolbox which will contain all sorts of functions for the genetic programming process\n",
    "toolbox = base.Toolbox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how to create a random expression/tree (using half-and-half intialization)\n",
    "toolbox.register(\"expr\", gp.genHalfAndHalf, pset=pset, min_=MIN_INITIAL_HEIGHT, max_=MAX_INITIAL_HEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classes for fitness, trees and individuals (using DEAP's creator module)\n",
    "creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "creator.create(\"Tree\", gp.PrimitiveTree)\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMin) # An individual is a list of single-output trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how to initialize a tree, individual or population\n",
    "toolbox.register(\"tree\", tools.initIterate, creator.Tree, toolbox.expr)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.tree, N_CLASSES_TO_USE)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitness function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how to compile a single tree and an individual\n",
    "toolbox.register(\"compile_tree\", gp.compile, pset=pset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how to compile an individual (list of trees)\n",
    "def compile_individual(individual):\n",
    "    # Compile all trees in the individual\n",
    "    funcs = [toolbox.compile_tree(t) for t in individual]\n",
    "    \n",
    "    # Create the function, which applies softmax over the outputs of the created lambda functions\n",
    "    def func(args):\n",
    "        def _softmax(x):\n",
    "            return exp(x)/np.sum(exp(x), axis=0)\n",
    "        return _softmax([f(*args) for f in funcs])\n",
    "    \n",
    "    # Return the created function\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add compile_individual to toolbox\n",
    "toolbox.register(\"compile_individual\", compile_individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define fitness function   \n",
    "def fitness(individual, sample_size):\n",
    "    # Compile the individual to obtain the corresponding function\n",
    "    func = toolbox.compile_individual(individual)\n",
    "    \n",
    "    # Define how to compute cross-entropy\n",
    "    def _cross_entropy(pred, label):\n",
    "        return -np.log(pred[label])\n",
    "    \n",
    "    # Create a list of samples to test, ensuring an equal number of samples from each class\n",
    "    sample_indices = []\n",
    "    samples_per_class = int(sample_size/N_CLASSES_TO_USE)\n",
    "    for c in range(N_CLASSES_TO_USE):\n",
    "        c_indices = np.where(Y_train == c)[0]\n",
    "        assert len(c_indices) >= samples_per_class, \\\n",
    "            f\"Class {c} has too few elements to reach the desired number of evaluation samples\"\n",
    "        sample_indices.extend(np.random.permutation(c_indices)[:samples_per_class])\n",
    "    \n",
    "    # Compute cross-entropy loss for each of the samples\n",
    "    losses = [_cross_entropy(func(X_train[i]), Y_train[i]) for i in sample_indices]\n",
    "    \n",
    "    # Return the average cross-entropy loss\n",
    "    return (np.average(losses),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the fitness function to the toolbox\n",
    "toolbox.register(\"evaluate\", fitness, sample_size=SAMPLE_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolution components\n",
    "\n",
    "##### Parent selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine the tools.selDoubleTournament function for our multi-tree individuals (all comments from the \n",
    "# original function have been removed to aid readability; the function remains unchanged except for the \n",
    "# usage of get_avg_height instead of len (as well as some differences in imports and python version)\n",
    "def selDoubleTournament(individuals, k, fitness_size, parsimony_size, fitness_first, fit_attr=\"fitness\"):\n",
    "    assert (1 <= parsimony_size <= 2), \"Parsimony tournament size has to be in the range [1, 2].\"\n",
    "\n",
    "    def _sizeTournament(individuals, k, select):\n",
    "        chosen = []\n",
    "        for i in range(k):\n",
    "            prob = parsimony_size / 2.\n",
    "            ind1, ind2 = select(individuals, k=2)\n",
    "\n",
    "            # This is the part that matters for our re-implementation: we use the average height of\n",
    "            # all trees instead of the length of the individual, which is equal for all individuals\n",
    "            if get_avg_height(ind1) > get_avg_height(ind2):\n",
    "                ind1, ind2 = ind2, ind1\n",
    "            elif get_avg_height(ind1) == get_avg_height(ind2):\n",
    "                prob = 0.5\n",
    "\n",
    "            chosen.append(ind1 if random.random() < prob else ind2)\n",
    "\n",
    "        return chosen\n",
    "\n",
    "    def _fitTournament(individuals, k, select):\n",
    "        chosen = []\n",
    "        for i in range(k):\n",
    "            aspirants = select(individuals, k=fitness_size)\n",
    "            chosen.append(max(aspirants, key=attrgetter(fit_attr)))\n",
    "        return chosen\n",
    "\n",
    "    if fitness_first:\n",
    "        tfit = partial(_fitTournament, select=tools.selRandom)\n",
    "        return _sizeTournament(individuals, k, tfit)\n",
    "    else:\n",
    "        tsize = partial(_sizeTournament, select=tools.selRandom)\n",
    "        return _fitTournament(individuals, k, tsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how to select parents (either a double tournament that controls for bloat or a single tournament that does not)\n",
    "if SIZE_TOURNAMENT:\n",
    "    toolbox.register(\"select\", selDoubleTournament, fitness_size=TOURNAMENT_SIZE, \n",
    "                     parsimony_size=P_SMALLER_WINS*2, fitness_first=False)\n",
    "else:\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=TOURNAMENT_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Crossover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how to perform crossover\n",
    "def crossover(ind1, ind2):\n",
    "    new_ind1, new_ind2 = [], []\n",
    "    for i in range(N_CLASSES_TO_USE):\n",
    "        tree1, tree2 = ind1[i], ind2[i]\n",
    "        if np.random.random() < P_CROSSOVER_PER_TREE:\n",
    "            tree1, tree2 = gp.cxOnePoint(tree1, tree2)\n",
    "        new_ind1.append(tree1)\n",
    "        new_ind2.append(tree2)\n",
    "    return (creator.Individual(new_ind1), creator.Individual(new_ind2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the crossover (\"mate\") function to the toolbox\n",
    "toolbox.register(\"mate\", crossover)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how to create a \"mutation tree\"\n",
    "toolbox.register(\"expr_mut\", gp.genHalfAndHalf, min_=MIN_MUTATION_HEIGHT, max_=MAX_MUTATION_HEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how to perform mutation\n",
    "def mutate(individual):\n",
    "    new_ind = []\n",
    "    for tree in individual:\n",
    "        if np.random.random() < P_MUTATION_PER_TREE:\n",
    "            new_ind.append(gp.mutUniform(tree, expr=toolbox.expr_mut, pset=pset)[0])\n",
    "        else:\n",
    "            new_ind.append(tree)\n",
    "    return creator.Individual(new_ind),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the mutation (\"mutate\") function to the toolbox\n",
    "toolbox.register(\"mutate\", mutate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Height boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define upper limits for height of trees (if limit is exceeded, a random parent is used instead)\n",
    "if HEIGHT_CAPPED:\n",
    "    toolbox.decorate(\"mate\", gp.staticLimit(key=get_avg_height, max_value=MAX_AVG_HEIGHT))\n",
    "    toolbox.decorate(\"mutate\", gp.staticLimit(key=get_avg_height, max_value=MAX_AVG_HEIGHT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe which kinds of statistics to keep track of\n",
    "stats_fit = tools.Statistics(key = lambda ind: ind.fitness.values)\n",
    "stats_height = tools.Statistics(key = get_avg_height)\n",
    "mstats = tools.MultiStatistics(fitness=stats_fit, height=stats_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe metrics to keep track of for each statistic\n",
    "mstats.register(\"min\", np.min)\n",
    "mstats.register(\"avg\", np.mean)\n",
    "mstats.register(\"std\", np.std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the genetic programming algorithm\n",
    "\n",
    "##### Running the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \t      \t                fitness                \t                 height                 \n",
      "   \t      \t---------------------------------------\t----------------------------------------\n",
      "gen\tnevals\tavg    \tgen\tmin    \tnevals\tstd    \tavg \tgen\tmin\tnevals\tstd     \n",
      "0  \t100   \t17.0929\t0  \t2.46781\t100   \t12.8284\t3.99\t0  \t3.4\t100   \t0.254362\n",
      "1  \t100   \t3.14175\t1  \t2.39192\t100   \t0.822477\t4.262\t1  \t3.4\t100   \t0.311378\n",
      "2  \t100   \t2.4713 \t2  \t2.35856\t100   \t0.0415294\t4.651\t2  \t4.2\t100   \t0.288616\n",
      "3  \t100   \t2.46656\t3  \t2.37719\t100   \t0.0394715\t4.881\t3  \t4.3\t100   \t0.413689\n",
      "4  \t100   \t2.46959\t4  \t2.37453\t100   \t0.0407035\t5.104\t4  \t4.5\t100   \t0.466245\n",
      "5  \t100   \t2.46938\t5  \t2.34323\t100   \t0.0437684\t5.247\t5  \t4.5\t100   \t0.384566\n",
      "6  \t100   \t2.46475\t6  \t2.34765\t100   \t0.0501196\t5.328\t6  \t4.6\t100   \t0.3603  \n",
      "7  \t100   \t2.45658\t7  \t2.3828 \t100   \t0.0362739\t5.409\t7  \t4.8\t100   \t0.360026\n",
      "8  \t100   \t2.45283\t8  \t2.35458\t100   \t0.0416403\t5.411\t8  \t4.9\t100   \t0.292881\n",
      "9  \t100   \t2.45112\t9  \t2.36563\t100   \t0.043838 \t5.36 \t9  \t4.9\t100   \t0.264575\n",
      "10 \t100   \t2.44712\t10 \t2.37649\t100   \t0.0368574\t5.217\t10 \t4.9\t100   \t0.238351\n",
      "11 \t100   \t2.43891\t11 \t2.32808\t100   \t0.0366176\t5.32 \t11 \t5  \t100   \t0.287054\n",
      "12 \t100   \t2.43773\t12 \t2.33206\t100   \t0.0454608\t5.283\t12 \t4.9\t100   \t0.23369 \n",
      "13 \t100   \t2.43669\t13 \t2.35363\t100   \t0.0377503\t5.366\t13 \t4.9\t100   \t0.251881\n",
      "14 \t100   \t2.43308\t14 \t2.31448\t100   \t0.0453164\t5.405\t14 \t5  \t100   \t0.192029\n",
      "15 \t100   \t2.41407\t15 \t2.31588\t100   \t0.0388432\t5.442\t15 \t5.2\t100   \t0.139413\n",
      "16 \t100   \t2.41544\t16 \t2.32017\t100   \t0.0418823\t5.519\t16 \t5.2\t100   \t0.185308\n",
      "17 \t100   \t2.41689\t17 \t2.31495\t100   \t0.0439988\t5.551\t17 \t5.2\t100   \t0.276946\n",
      "18 \t100   \t2.41254\t18 \t2.3203 \t100   \t0.0389811\t5.626\t18 \t5.2\t100   \t0.172986\n",
      "19 \t100   \t2.42081\t19 \t2.3022 \t100   \t0.0623689\t5.697\t19 \t5.2\t100   \t0.171146\n",
      "20 \t100   \t2.40925\t20 \t2.30027\t100   \t0.0642151\t5.761\t20 \t5.4\t100   \t0.180497\n",
      "21 \t100   \t2.40116\t21 \t2.29183\t100   \t0.0459184\t5.865\t21 \t5.5\t100   \t0.238904\n",
      "22 \t100   \t2.38516\t22 \t2.30609\t100   \t0.0386336\t5.776\t22 \t5.4\t100   \t0.161938\n",
      "23 \t100   \t2.38605\t23 \t2.28872\t100   \t0.0409713\t5.877\t23 \t5.2\t100   \t0.18647 \n",
      "24 \t100   \t2.38152\t24 \t2.2962 \t100   \t0.0384389\t5.878\t24 \t5.4\t100   \t0.191614\n",
      "25 \t100   \t2.37588\t25 \t2.27667\t100   \t0.042699 \t5.948\t25 \t5.3\t100   \t0.219764\n",
      "26 \t100   \t2.37503\t26 \t2.28313\t100   \t0.0411915\t5.97 \t26 \t5.4\t100   \t0.241454\n",
      "27 \t100   \t2.36266\t27 \t2.2812 \t100   \t0.0329159\t6.176\t27 \t5.6\t100   \t0.19956 \n",
      "28 \t100   \t2.35899\t28 \t2.26052\t100   \t0.0340272\t6.219\t28 \t5.5\t100   \t0.203811\n",
      "29 \t100   \t2.36041\t29 \t2.27541\t100   \t0.0364949\t6.246\t29 \t5.8\t100   \t0.2128  \n",
      "30 \t100   \t2.35747\t30 \t2.2855 \t100   \t0.0275959\t6.17 \t30 \t5.5\t100   \t0.269629\n",
      "31 \t100   \t2.3617 \t31 \t2.28222\t100   \t0.0348735\t6.155\t31 \t5.7\t100   \t0.256661\n",
      "32 \t100   \t2.36812\t32 \t2.29807\t100   \t0.0344365\t6.053\t32 \t5.7\t100   \t0.219297\n",
      "33 \t100   \t2.37507\t33 \t2.2701 \t100   \t0.131859 \t5.983\t33 \t5.6\t100   \t0.270575\n",
      "34 \t100   \t2.37414\t34 \t2.29078\t100   \t0.155525 \t5.997\t34 \t5.6\t100   \t0.244726\n",
      "35 \t100   \t2.36759\t35 \t2.27254\t100   \t0.0363886\t6.063\t35 \t5.5\t100   \t0.287282\n",
      "36 \t100   \t2.37049\t36 \t2.2615 \t100   \t0.0416182\t6.082\t36 \t5.5\t100   \t0.276543\n",
      "37 \t100   \t2.37124\t37 \t2.28386\t100   \t0.0370278\t6.107\t37 \t5.6\t100   \t0.268423\n",
      "38 \t100   \t2.36728\t38 \t2.29767\t100   \t0.0339278\t6.137\t38 \t5.7\t100   \t0.270427\n",
      "39 \t100   \t2.37131\t39 \t2.29604\t100   \t0.0361146\t6.245\t39 \t5.7\t100   \t0.307042\n",
      "40 \t100   \t2.37077\t40 \t2.31316\t100   \t0.0276284\t6.227\t40 \t5.6\t100   \t0.234459\n",
      "41 \t100   \t2.3755 \t41 \t2.29628\t100   \t0.0682605\t6.202\t41 \t5.6\t100   \t0.200988\n",
      "42 \t100   \t2.35852\t42 \t2.27591\t100   \t0.0347277\t6.151\t42 \t5.3\t100   \t0.365375\n",
      "43 \t100   \t2.35164\t43 \t2.27574\t100   \t0.0363852\t5.893\t43 \t4.8\t100   \t0.520049\n",
      "44 \t100   \t2.41061\t44 \t2.25648\t100   \t0.507438 \t5.514\t44 \t4.9\t100   \t0.367157\n",
      "45 \t100   \t2.35174\t45 \t2.26934\t100   \t0.0559293\t5.298\t45 \t4.9\t100   \t0.265699\n",
      "46 \t100   \t2.36652\t46 \t2.25333\t100   \t0.145187 \t5.165\t46 \t4.8\t100   \t0.233827\n",
      "47 \t100   \t2.49949\t47 \t2.21392\t100   \t1.5961   \t5.148\t47 \t4.8\t100   \t0.262099\n",
      "48 \t100   \t2.35557\t48 \t2.24495\t100   \t0.127394 \t5.189\t48 \t4.8\t100   \t0.281743\n",
      "49 \t100   \t2.50773\t49 \t2.22619\t100   \t1.85826  \t5.085\t49 \t4.8\t100   \t0.226881\n",
      "50 \t100   \t2.44001\t50 \t2.20635\t100   \t1.25101  \t5.029\t50 \t4.8\t100   \t0.182371\n",
      "51 \t100   \t2.31455\t51 \t2.22469\t100   \t0.0399372\t5.061\t51 \t4.8\t100   \t0.173144\n"
     ]
    }
   ],
   "source": [
    "# Run the evolutionary algorithm\n",
    "pop = toolbox.population(POPULATION_SIZE)\n",
    "hof = tools.HallOfFame(1)\n",
    "pop, log = algorithms.eaSimple(population=pop, toolbox=toolbox, cxpb=P_CROSSOVER, mutpb=P_MUTATION, \n",
    "                                     ngen=N_GENERATIONS, stats=mstats, halloffame=hof, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Wrapping up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results\n",
    "with open(RESULTS_FILENAME, \"wb\") as f:\n",
    "    pickle.dump((pop, log, hof), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract generation IDs, minimum fitnesses and average total heights per generation\n",
    "gen = log.select(\"gen\")\n",
    "fitness_best = log.chapters[\"fitness\"].select(\"min\") \n",
    "height_avg = log.chapters[\"height\"].select(\"avg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot line for minimum fitness\n",
    "fig, fit_ax = plt.subplots()\n",
    "fit_line = fit_ax.plot(gen, fitness_best, \"b-\", label=\"Best Fitness\")\n",
    "fit_ax.set_xlabel(\"Generation\")\n",
    "fit_ax.set_ylabel(f\"Cross-entropy loss\", color=\"b\")\n",
    "for tl in fit_ax.get_yticklabels():\n",
    "    tl.set_color(\"b\")\n",
    "\n",
    "# Plot line for average total height\n",
    "height_ax = fit_ax.twinx()\n",
    "height_line = height_ax.plot(gen, height_avg, \"r-\", label=\"Average Height\")\n",
    "height_ax.set_ylabel(\"Height\", color=\"r\")\n",
    "for tl in height_ax.get_yticklabels():\n",
    "    tl.set_color(\"r\")\n",
    "\n",
    "# Add legend\n",
    "lines = fit_line + height_line\n",
    "labs = [l.get_label() for l in lines]\n",
    "fit_ax.legend(lines, labs, loc=\"upper center\")\n",
    "\n",
    "# Show the result\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the best individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ind = hof[0]\n",
    "print(f\"Fitness of best individual: {best_ind.fitness}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Printing trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the trees of the best individual\n",
    "print_trees(best_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Computing training & validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving predictions from an individual\n",
    "def get_predictions(individual, X):\n",
    "    func = toolbox.compile_individual(individual)\n",
    "    predictions = []\n",
    "    for i in range(X.shape[0]):\n",
    "        predictions.append(np.argmax(func(X[i])))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute accuracy of predictions\n",
    "def compute_accuracy(Y_pred, Y_true):\n",
    "    n_correct = np.sum(Y_pred == Y_true)\n",
    "    return n_correct/Y_true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve predictions of the best individual on the training and validation sets\n",
    "Y_train_pred = get_predictions(best_ind, X_train)\n",
    "Y_test_pred = get_predictions(best_ind, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print training and validation accuracies of the best individual\n",
    "print(f\"Training accuracy: {compute_accuracy(Y_train_pred, Y_train)}\")\n",
    "print(f\"Validation accuracy: {compute_accuracy(Y_test_pred, Y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrices\n",
    "cm_train = confusion_matrix(Y_train, Y_train_pred, labels=range(N_CLASSES_TO_USE))\n",
    "cm_test = confusion_matrix(Y_test, Y_test_pred, labels=range(N_CLASSES_TO_USE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure\n",
    "fig, ax = plt.subplots(1,2, figsize=(11,4))\n",
    "\n",
    "# Plot confusion matrix for training data\n",
    "sns.heatmap(cm_train, annot=True, fmt='g', ax=ax[0], cmap=\"Blues\")\n",
    "ax[0].set_xlabel('Predicted labels')\n",
    "ax[0].set_ylabel('True labels')\n",
    "ax[0].set_title('Confusion matrix for training data')\n",
    "\n",
    "# Plot confusion matrix for validation data\n",
    "sns.heatmap(cm_test, annot=True, fmt='g', ax=ax[1], cmap=\"Blues\")\n",
    "ax[1].set_xlabel('Predicted labels')\n",
    "ax[1].set_ylabel('True labels')\n",
    "ax[1].set_title('Confusion matrix for validation data')\n",
    "\n",
    "# Show the result\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Used features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract input tallies from best individual\n",
    "input_tallies = []\n",
    "for tree in best_ind:\n",
    "    inputs_used = list(map(int, re.findall(\"[0-9]+\", str(tree))))\n",
    "    input_tally = np.zeros(X_train.shape[1])\n",
    "    for arg in inputs_used:\n",
    "        input_tally[arg] += 1\n",
    "    input_tallies.append(input_tally)\n",
    "\n",
    "# Create plots of the inputs (pixels) used in the tree of the best individual for each class\n",
    "# Note: for the best-looking plot, this implementation assumes that N_CLASSES_TO_USE is set to 10\n",
    "fig, ax = plt.subplots(2, 5, figsize=(16,5))\n",
    "ax = ax.ravel()\n",
    "for i, tally in enumerate(input_tallies):\n",
    "    img_shape = int(math.sqrt(X_train.shape[1]))\n",
    "    ax[i].imshow(np.array(tally).reshape(img_shape, img_shape), clim=(0,np.max(input_tallies)))\n",
    "    ax[i].axis(\"off\")\n",
    "    ax[i].set_title(f\"Pixels used for class {i}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot image of all inputs used in the tree\n",
    "plt.imshow(np.sum(input_tallies, axis=0).reshape(16,16))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Pixels used in the entire tree\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Computing - Project\n",
    "#### Submission by group 25 (Chihab Amghane, Max Driessen, Jordy Naus)\n",
    "\n",
    "The code below uses the DEAP framework (https://github.com/deap/deap), which is a very intuitive framework for evolutionary algorithms and genetic programming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEAP\n",
    "from deap import gp, base, tools, creator, algorithms\n",
    "\n",
    "# Data processing and plotting\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Requirements for the algorithm\n",
    "from operator import attrgetter\n",
    "from functools import partial\n",
    "\n",
    "# Standard python imports\n",
    "import random, pickle, math, re, os, copy\n",
    "import numpy as np\n",
    "\n",
    "import pdb\n",
    "# Magic for inline plots\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp(x):\n",
    "    return np.exp(np.clip(x, -float('inf'), 709.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset parameters\n",
    "DATASET = \"MNIST\" # choose from {\"MNIST\", \"Fashion-MNIST\"} \n",
    "N_CLASSES_TO_USE = 10 # at most 10\n",
    "USE_NORMALIZATION = True\n",
    "USE_ANTI_ALIASING = False\n",
    "\n",
    "# Individual tree parameters\n",
    "N_INITIAL_CONNECTIONS = 100\n",
    "CONNECTIONS_CAPPED = True\n",
    "MAX_CONNECTIONS = 300\n",
    "\n",
    "# Fitness parameters\n",
    "N_SAMPLES_TO_TEST = 200\n",
    "\n",
    "# Evolution parameters\n",
    "N_GENERATIONS = 500\n",
    "POPULATION_SIZE = 100\n",
    "\n",
    "TOURNAMENT_SIZE = 10\n",
    "SIZE_TOURNAMENT = True\n",
    "P_SMALLER_WINS = 0.65\n",
    "\n",
    "P_ADD_CONNECTION = 0.5\n",
    "P_REMOVE_CONNECTION = 0.3\n",
    "P_ADD_NODE = 0.2\n",
    "P_REMOVE_NODE = 0.2\n",
    "P_CHANGE_OPERATOR = 0.3\n",
    "\n",
    "# Filename parameters\n",
    "RESULTS_FILENAME = \"results.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the correct data filename\n",
    "filename = f\"{DATASET}-{N_CLASSES_TO_USE}{'-Norm' if USE_NORMALIZATION else ''}{'-AA' if USE_ANTI_ALIASING else ''}.pkl\"\n",
    "\n",
    "# If the data has not yet been preprocessed in the specified way, do so now\n",
    "if not os.path.exists(os.path.join(\"data\", filename)):\n",
    "    print(\"Preprocessed dataset does not exist yet, creating now.\")\n",
    "    os.system(f\"python Preprocessing.py -d {DATASET} -c {N_CLASSES_TO_USE}\" + \\\n",
    "              f\"{' --aa' if USE_ANTI_ALIASING else ''}{' --n' if USE_NORMALIZATION else ''}\")\n",
    "\n",
    "# Load the preprocessed data\n",
    "with open(os.path.join(\"data\", filename), \"rb\") as f:\n",
    "    (X_train, Y_train), (X_test, Y_test) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define operators (with a variable number of inputs)\n",
    "def linear(*args):\n",
    "    return sum(args)\n",
    "\n",
    "def inverse(*args):\n",
    "    return -sum(args)\n",
    "\n",
    "def tanh(*args):\n",
    "    return math.tanh(sum(args))\n",
    "\n",
    "def sigmoid(*args):\n",
    "    return 1.0/(1.0 + exp(-sum(args)))\n",
    "\n",
    "def step(*args):\n",
    "    return float(sum(args) >= 0)\n",
    "\n",
    "def sine(*args):\n",
    "    return math.sin(sum(args))\n",
    "\n",
    "def cosine(*args):\n",
    "    return math.cos(sum(args))\n",
    "\n",
    "def gaussian(*args):\n",
    "    return 0.5*sum(args)*(1.0+math.tanh(math.sqrt(2.0/math.pi)*(sum(args) + 0.044715*sum(args)**3)))\n",
    "\n",
    "# def gaussian(*args):\n",
    "#     return exp( -(sum(args)*sum(args)) / 2.0 )\n",
    "                          \n",
    "def absolute(*args):\n",
    "    return abs(sum(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dictionary of functions for compiling\n",
    "function_context = {'linear':linear, 'inverse':inverse, 'tanh':tanh, 'sigmoid':sigmoid, 'step':step, \n",
    "                    'sine':sine, 'cosine':cosine, 'gaussian':gaussian, 'absolute':absolute}\n",
    "\n",
    "# Create lists of function and argument names\n",
    "function_names = list(function_context.keys())\n",
    "argument_names = [f\"ARG{i}\" for i in range(X_train.shape[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining individuals\n",
    "\n",
    "##### Defining nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic Node class\n",
    "class Node:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.parents = []\n",
    "        self.children = []\n",
    "    \n",
    "    def __str__(self):\n",
    "        raise NotImplementedError(\"String function is only implemented for subclasses\")\n",
    "\n",
    "# Class for terminal nodes (inputs)\n",
    "class TerminalNode(Node):\n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "\n",
    "# Class for primitive nodes (internals + outputs)\n",
    "class PrimitiveNode(Node):\n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.name}({', '.join([str(child) for child in self.children])})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for multi-output trees\n",
    "class MultiClassTree:\n",
    "    def __init__(self, n_inputs, n_outputs, n_initial_connections):\n",
    "        # Initialize lists of input, output and internal nodes\n",
    "        self.inputs = [TerminalNode(argument_names[i]) for i in range(n_inputs)]\n",
    "        self.outputs = [PrimitiveNode(\"sigmoid\") for _ in range(n_outputs)]\n",
    "        self.internals = []\n",
    "        \n",
    "        # Add initial connections so that initial tree is valid\n",
    "        self.n_connections = n_initial_connections\n",
    "        for output in self.outputs:\n",
    "            initial_children = random.choices(self.inputs, k=n_initial_connections)\n",
    "            output.children.extend(initial_children)\n",
    "            for child in initial_children:\n",
    "                child.parents.append(output)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"MultiClassTree with {len(self.inputs)} inputs, \" + \\\n",
    "                                   f\"{len(self.outputs)} outputs and \" + \\\n",
    "                                   f\"{len(self.internals)} internal nodes.\\n\"\n",
    "    \n",
    "    # Retrieving output function strings\n",
    "    def get_strings(self):\n",
    "        try:\n",
    "            return [str(output) for output in self.outputs]\n",
    "        except RecursionError:\n",
    "            print(\"Maximum recursion depth reached\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialize the toolbox which will contain all sorts of functions for the genetic programming process\n",
    "toolbox = base.Toolbox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chb3k/anaconda3/envs/py37nc/lib/python3.8/site-packages/deap/creator.py:138: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "/home/chb3k/anaconda3/envs/py37nc/lib/python3.8/site-packages/deap/creator.py:138: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    }
   ],
   "source": [
    "# Define classes for fitness and individuals (using DEAP's creator module)\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", MultiClassTree, fitness=creator.FitnessMax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how to initialize an individual or population\n",
    "toolbox.register(\"individual\", creator.Individual, X_train.shape[1], \n",
    "                               N_CLASSES_TO_USE, N_INITIAL_CONNECTIONS)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitness function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling a tree into a function\n",
    "def compile_multiclasstree(tree):\n",
    "    strings = tree.get_strings()\n",
    "    funcs = [eval(f\"lambda {', '.join(argument_names)}: {string}\", function_context, {}) for string in strings]\n",
    "    def func(args):\n",
    "        return [f(*args) for f in funcs]\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add compile function to toolbox\n",
    "toolbox.register(\"compile\", compile_multiclasstree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define fitness function   \n",
    "def fitness(individual, n_samples_to_test):\n",
    "    # Compile the functions corresponding to the individual\n",
    "    func = toolbox.compile(individual)\n",
    "    \n",
    "    # Create a list of samples to test, ensuring an equal number of samples from each class\n",
    "    sample_indices = []\n",
    "    n_samples_per_class = int(n_samples_to_test/N_CLASSES_TO_USE)\n",
    "    for c in range(N_CLASSES_TO_USE):\n",
    "        c_indices = np.where(Y_train == c)[0]\n",
    "        assert len(c_indices) >= n_samples_per_class, \\\n",
    "            f\"Class {c} has too few elements to reach the desired number of evaluation samples\"\n",
    "        sample_indices.extend(np.random.permutation(c_indices)[:n_samples_per_class])\n",
    "    \n",
    "    # Compute cross-entropy loss for each of the samples\n",
    "    results = []\n",
    "    for i in sample_indices:\n",
    "        X_sample, Y_sample = X_train[i], Y_train[i]\n",
    "        output = func(X_sample)\n",
    "        results.append(np.argmax(output) == Y_sample)\n",
    "    \n",
    "    # Return the average cross-entropy loss\n",
    "    return (np.average(results),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the fitness function to the toolbox\n",
    "toolbox.register(\"evaluate\", fitness, n_samples_to_test=N_SAMPLES_TO_TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evolution components\n",
    "\n",
    "##### Parent selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redefine the tools.selDoubleTournament function for our multi-tree individuals (all comments from the original function have been removed to aid readability; the function remains unchanged \n",
    "# except for the usage of get_total_size instead of len (as well as some differences in imports and python version)\n",
    "def selDoubleTournament(individuals, k, fitness_size, parsimony_size, fitness_first,cull_ratio = 0.3, fit_attr=\"fitness\"):\n",
    "    assert (1 <= parsimony_size <= 2), \"Parsimony tournament size has to be in the range [1, 2].\"\n",
    "\n",
    "    def _sizeTournament(individuals, k, select):\n",
    "        chosen = []\n",
    "        for i in range(k):\n",
    "            prob = parsimony_size / 2.\n",
    "            ind1, ind2 = select(individuals, k=2)\n",
    "\n",
    "            # This is the part that matters for our re-implementation: we use the total size of\n",
    "            # all trees instead of the length of the individual, which is equal for all individuals\n",
    "            if ind1.n_connections > ind2.n_connections:\n",
    "                ind1, ind2 = ind2, ind1\n",
    "            elif ind1.n_connections == ind2.n_connections:\n",
    "                prob = 0.5\n",
    "\n",
    "            chosen.append(ind1 if random.random() < prob else ind2)\n",
    "\n",
    "        return chosen\n",
    "\n",
    "    def _fitTournament(individuals, k, select):\n",
    "        chosen = []\n",
    "        for i in range(k):\n",
    "            sorted_by_rank = select(individuals, k=len(individuals))\n",
    "            number_to_cull = int(cull_ratio * len(individuals))\n",
    "            aspirants = sorted_by_rank[:number_to_cull]\n",
    "            pdb.set_trace()\n",
    "            chosen.append(max(aspirants, key=attrgetter(fit_attr)))\n",
    "        return chosen\n",
    "\n",
    "    if fitness_first:\n",
    "        tfit = partial(_fitTournament, select=tools.selNSGA2) #select=tools.selRandom)\n",
    "        return _sizeTournament(individuals, k, tfit)\n",
    "    else:\n",
    "        tsize = partial(_sizeTournament, select=tools.selRandom)\n",
    "        return _fitTournament(individuals, k, tsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how to select parents (either a double tournament that controls for bloat or a single tournament that does not)\n",
    "if SIZE_TOURNAMENT:\n",
    "    toolbox.register(\"select\", selDoubleTournament, fitness_size=TOURNAMENT_SIZE, \n",
    "                     parsimony_size=P_SMALLER_WINS*2, fitness_first=False)\n",
    "else:\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=TOURNAMENT_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate(tree):\n",
    "    \n",
    "    tree = copy.deepcopy(tree)\n",
    "    \n",
    "    def _remove_connection():\n",
    "        possible_parents = [t for t in tree.outputs + tree.internals if len(t.children) > 1]\n",
    "        if not possible_parents:\n",
    "            return\n",
    "        parent = random.choice(possible_parents)\n",
    "        child_to_remove = random.choice(parent.children)\n",
    "        parent.children.remove(child_to_remove)\n",
    "        child_to_remove.parents.remove(parent)\n",
    "        tree.n_connections -= 1\n",
    "    \n",
    "    def _add_connection():\n",
    "        def _is_ancestor(node1, node2):\n",
    "            return node1 in [node2] + node2.parents or any([_is_ancestor(node1, node3) for node3 in node2.parents])\n",
    "        valid_child = False\n",
    "        while not valid_child:\n",
    "            parent = random.choice(tree.outputs + tree.internals)\n",
    "            child = random.choice(tree.inputs + tree.internals)\n",
    "            valid_child = not _is_ancestor(child, parent)\n",
    "        child.parents.append(parent)\n",
    "        parent.children.append(child)\n",
    "        tree.n_connections += 1\n",
    "        \n",
    "    def _add_node():\n",
    "        parent = random.choice(tree.outputs + tree.internals)\n",
    "        children = random.sample(parent.children, random.randint(1, len(parent.children)))\n",
    "        [parent.children.remove(child) for child in children]\n",
    "\n",
    "        node = PrimitiveNode(random.choice(function_names))\n",
    "        parent.children.append(node)\n",
    "        node.parents.append(parent)\n",
    "        node.children.extend(children)\n",
    "        for child in children:\n",
    "            child.parents.append(node)\n",
    "        tree.internals.append(node)\n",
    "        tree.n_connections += 1\n",
    "\n",
    "    def _remove_node():\n",
    "        if not tree.internals:\n",
    "            return\n",
    "        node = random.choice(tree.internals)\n",
    "        for parent in node.parents:\n",
    "            parent.children.extend(node.children)\n",
    "        for child in node.children:\n",
    "            child.parents.extend(node.parents)\n",
    "        tree.internals.remove(node)\n",
    "        connection_change = len(node.children) * (len(node.parents)-1) - len(node.parents)\n",
    "        tree.n_connections += connection_change\n",
    "\n",
    "    def _change_operator():\n",
    "        if not tree.internals:\n",
    "            return\n",
    "        node = random.choice(tree.internals)\n",
    "        node.name = random.choice(function_names)\n",
    "        \n",
    "    if random.random() < P_ADD_CONNECTION:\n",
    "        _add_connection()\n",
    "    if random.random() < P_REMOVE_CONNECTION:\n",
    "        _remove_connection()\n",
    "    if random.random() < P_ADD_NODE:\n",
    "        _add_node()\n",
    "    if random.random() < P_REMOVE_NODE:\n",
    "        _remove_node()\n",
    "    if random.random() < P_CHANGE_OPERATOR:\n",
    "        _change_operator()\n",
    "        \n",
    "    return tree,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the mutation (\"mutate\") function to the toolbox\n",
    "toolbox.register(\"mutate\", mutate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Height boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define upper limits for height of trees (if limit is exceeded, a random parent is used instead)\n",
    "if CONNECTIONS_CAPPED:\n",
    "    toolbox.decorate(\"mutate\", gp.staticLimit(key=lambda ind: ind.n_connections, max_value=MAX_CONNECTIONS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe which kinds of statistics to keep track of\n",
    "stats_fit = tools.Statistics(key = lambda ind: ind.fitness.values)\n",
    "stats_connections = tools.Statistics(key = lambda ind: ind.n_connections)\n",
    "mstats = tools.MultiStatistics(fitness=stats_fit, connections=stats_connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe metrics to keep track of for each statistic\n",
    "mstats.register(\"avg\", np.mean)\n",
    "mstats.register(\"std\", np.std)\n",
    "mstats.register(\"min\", np.min)\n",
    "mstats.register(\"max\", np.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the genetic programming algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \t      \t                connections                \t                     fitness                     \n",
      "   \t      \t-------------------------------------------\t-------------------------------------------------\n",
      "gen\tnevals\tavg\tgen\tmax\tmin\tnevals\tstd\tavg   \tgen\tmax \tmin \tnevals\tstd      \n",
      "0  \t100   \t100\t0  \t100\t100\t100   \t0  \t0.1055\t0  \t0.21\t0.04\t100   \t0.0353235\n",
      "> \u001b[0;32m<ipython-input-41-d91cbe7b32ef>\u001b[0m(28)\u001b[0;36m_fitTournament\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     26 \u001b[0;31m            \u001b[0maspirants\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindividuals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindividuals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     27 \u001b[0;31m            \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 28 \u001b[0;31m            \u001b[0mchosen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maspirants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     29 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mchosen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     30 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> cont\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Individual' object has no attribute 'rank'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-6dc7ba53f945>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPOPULATION_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mhof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHallOfFame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m pop, log = algorithms.eaSimple(population=pop, toolbox=toolbox, cxpb=0.0, mutpb=1.0, \n\u001b[0m\u001b[1;32m      4\u001b[0m                                ngen=N_GENERATIONS, stats=mstats, halloffame=hof, verbose=True)\n",
      "\u001b[0;32m~/anaconda3/envs/py37nc/lib/python3.8/site-packages/deap/algorithms.py\u001b[0m in \u001b[0;36meaSimple\u001b[0;34m(population, toolbox, cxpb, mutpb, ngen, stats, halloffame, verbose)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mgen\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngen\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;31m# Select the next generation individuals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0moffspring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;31m# Vary the pool of individuals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-d91cbe7b32ef>\u001b[0m in \u001b[0;36mselDoubleTournament\u001b[0;34m(individuals, k, fitness_size, parsimony_size, fitness_first, fit_attr)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mtsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sizeTournament\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselRandom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_fitTournament\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindividuals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-d91cbe7b32ef>\u001b[0m in \u001b[0;36m_fitTournament\u001b[0;34m(individuals, k, select)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0maspirants\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindividuals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindividuals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mchosen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maspirants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mchosen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Individual' object has no attribute 'rank'"
     ]
    }
   ],
   "source": [
    "pop = toolbox.population(POPULATION_SIZE)\n",
    "hof = tools.HallOfFame(1)\n",
    "pop, log = algorithms.eaSimple(population=pop, toolbox=toolbox, cxpb=0.0, mutpb=1.0, \n",
    "                               ngen=N_GENERATIONS, stats=mstats, halloffame=hof, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results\n",
    "with open(RESULTS_FILENAME, \"wb\") as f:\n",
    "    pickle.dump((pop, log, hof), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract generation IDs, minimum fitnesses and average total heights per generation\n",
    "gen = log.select(\"gen\")\n",
    "fitness_best = log.chapters[\"fitness\"].select(\"max\") \n",
    "conn_avg = log.chapters[\"connections\"].select(\"avg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot line for minimum fitness\n",
    "fig, fit_ax = plt.subplots()\n",
    "fit_line = fit_ax.plot(gen, fitness_best, \"b-\", label=\"Best Fitness\")\n",
    "fit_ax.set_xlabel(\"Generation\")\n",
    "fit_ax.set_ylabel(f\"Accuracy\", color=\"b\")\n",
    "for tl in fit_ax.get_yticklabels():\n",
    "    tl.set_color(\"b\")\n",
    "\n",
    "# Plot line for average total height\n",
    "height_ax = fit_ax.twinx()\n",
    "height_line = height_ax.plot(gen, conn_avg, \"r-\", label=\"Average Number of Connections\")\n",
    "height_ax.set_ylabel(\"Average height\", color=\"r\")\n",
    "for tl in height_ax.get_yticklabels():\n",
    "    tl.set_color(\"r\")\n",
    "\n",
    "# Add legend\n",
    "lines = fit_line + height_line\n",
    "labs = [l.get_label() for l in lines]\n",
    "fit_ax.legend(lines, labs, loc=\"upper center\")\n",
    "\n",
    "# Show the result\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the best individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ind = hof[0]\n",
    "print(f\"Fitness of best individual: {best_ind.fitness}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Printing trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the trees of the best individual\n",
    "for string in best_ind.get_strings():\n",
    "    print(f\"{string}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Computing training & validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving predictions from an individual\n",
    "def get_predictions(individual, X):\n",
    "    func = compile_multiclasstree(individual)\n",
    "    predictions = []\n",
    "    for i in range(X.shape[0]):\n",
    "        outputs_i = func(X[i])\n",
    "        predictions.append(np.argmax(outputs_i))\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve predictions of the best individual on the training and validation sets\n",
    "Y_train_pred = get_predictions(best_ind, X_train)\n",
    "Y_test_pred = get_predictions(best_ind, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute accuracy of predictions\n",
    "def compute_accuracy(Y_pred, Y_true):\n",
    "    n_correct = np.sum(Y_pred == Y_true)\n",
    "    return n_correct/Y_true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print training and validation accuracies of the best individual\n",
    "print(f\"Training accuracy: {compute_accuracy(Y_train_pred, Y_train)}\")\n",
    "print(f\"Validation accuracy: {compute_accuracy(Y_test_pred, Y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrices\n",
    "cm_train = confusion_matrix(Y_train, Y_train_pred, labels=range(N_CLASSES_TO_USE))\n",
    "cm_test = confusion_matrix(Y_test, Y_test_pred, labels=range(N_CLASSES_TO_USE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure\n",
    "fig, ax = plt.subplots(1,2, figsize=(11,4))\n",
    "\n",
    "# Plot confusion matrix for training data\n",
    "sns.heatmap(cm_train, annot=True, fmt='g', ax=ax[0], cmap=\"Blues\")\n",
    "ax[0].set_xlabel('Predicted labels')\n",
    "ax[0].set_ylabel('True labels')\n",
    "ax[0].set_title('Confusion matrix for training data')\n",
    "\n",
    "# Plot confusion matrix for validation data\n",
    "sns.heatmap(cm_test, annot=True, fmt='g', ax=ax[1], cmap=\"Blues\")\n",
    "ax[1].set_xlabel('Predicted labels')\n",
    "ax[1].set_ylabel('True labels')\n",
    "ax[1].set_title('Confusion matrix for validation data')\n",
    "\n",
    "# Show the result\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Used features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots of the inputs (pixels) used in the tree of the best individual for each class \n",
    "fig, ax = plt.subplots(1, N_CLASSES_TO_USE, figsize=(20,20/N_CLASSES_TO_USE))\n",
    "for i, tree in enumerate(best_ind.get_strings()):\n",
    "    inputs_used = list(map(int, re.findall(\"[0-9]+\", str(tree))))\n",
    "    input_tallies = np.zeros(X_train.shape[1])\n",
    "    for arg in inputs_used:\n",
    "        input_tallies[arg] += 1\n",
    "    img_shape = int(math.sqrt(X_train.shape[1]))\n",
    "    ax[i].imshow(input_tallies.reshape(img_shape, img_shape))\n",
    "    ax[i].axis(\"off\")\n",
    "    ax[i].set_title(f\"Pixels used for class {i}\") \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
